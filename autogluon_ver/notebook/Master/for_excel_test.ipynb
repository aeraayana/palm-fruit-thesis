{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Params on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.multimodal import MultiModalPredictor\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import datetime\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test datasets\n",
    "train_df = pd.read_csv(\"E:/Current_Workdir/palm-fruit-classification/data/clean/train_df.csv\")\n",
    "test_df = pd.read_csv(\"E:/Current_Workdir/palm-fruit-classification/data/clean/test_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(train_df[\"label_text\"]), y=train_df[\"label_text\"])\n",
    "class_weights_list = class_weights.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for each model\n",
    "hyperparam_1 = {\n",
    "    \"Model\": \"EfficientNet\", \"gamma\": 2.255197916, \"learning rate\": 0.000198215, \"batch_size\": 16, \"epoch\": 13\n",
    "}\n",
    "hyperparam_2 = {\n",
    "    \"Model\": \"EfficientNet\", \"gamma\": 2.49282, \"learning rate\": 0.000128404, \"batch_size\": 128, \"epoch\": 7\n",
    "}\n",
    "hyperparam_3 = {\n",
    "    \"Model\": \"EfficientNet\", \"gamma\": 2.60701, \"learning rate\": 0.000942346, \"batch_size\": 16, \"epoch\": 8\n",
    "}\n",
    "hyperparam_4 = {\n",
    "    \"Model\": \"ResNet18\", \"gamma\": 2.101006332, \"learning rate\": 0.000719425, \"batch_size\": 8, \"epoch\": 9\n",
    "}\n",
    "hyperparam_5 = {\n",
    "    \"Model\": \"ResNet18\", \"gamma\": 2.45143, \"learning rate\": 0.000269354, \"batch_size\": 256, \"epoch\": 7\n",
    "}\n",
    "hyperparam_6 = {\n",
    "    \"Model\": \"ResNet18\", \"gamma\": 2.10302, \"learning rate\": 0.000678854, \"batch_size\": 8, \"epoch\": 9\n",
    "}\n",
    "hyperparam_7 = {\n",
    "    \"Model\": \"EfficientNetv2\", \"gamma\": 2.105304731, \"learning rate\": 0.000357808, \"batch_size\": 16, \"epoch\": 7\n",
    "}\n",
    "hyperparam_8 = {\n",
    "    \"Model\": \"EfficientNetv2\", \"gamma\": 2.62577, \"learning rate\": 0.000262012, \"batch_size\": 64, \"epoch\": 18\n",
    "}\n",
    "hyperparam_9 = {\n",
    "    \"Model\": \"EfficientNetv2\", \"gamma\": 2.25188, \"learning rate\": 0.000339079, \"batch_size\": 128, \"epoch\": 6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create the model path and define hyperparameters\n",
    "def create_and_train_model(hyperparam, idx):\n",
    "    model_name = hyperparam['Model']\n",
    "    gamma = hyperparam['gamma']\n",
    "    learning_rate = hyperparam['learning rate']\n",
    "    batch_size = hyperparam['batch_size']\n",
    "    epochs = hyperparam['epoch']\n",
    "\n",
    "    # Set model-specific identifier\n",
    "    if model_name == \"EfficientNet\":\n",
    "        model_checkpoint = \"efficientnet_b2\"\n",
    "    elif model_name == \"ResNet18\":\n",
    "        model_checkpoint = \"resnet18\"\n",
    "    elif model_name == \"EfficientNetv2\":\n",
    "        model_checkpoint = \"tf_efficientnetv2_s.in1k\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {model_name}\")\n",
    "\n",
    "    # Set training folder name\n",
    "    now = datetime.datetime.now()\n",
    "    timestamp_str = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    model_path = f\"../../model/master/train_{model_name}_{idx}_{timestamp_str}\"\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "    # Define hyperparameters\n",
    "    hyperparameters = {\n",
    "        \"optimization.learning_rate\": learning_rate,\n",
    "        \"optimization.max_epochs\": int(epochs),\n",
    "        \"env.batch_size\": int(batch_size),\n",
    "        \"optimization.loss_function\": \"focal_loss\",\n",
    "        \"optimization.focal_loss.alpha\": class_weights_list,\n",
    "        \"optimization.focal_loss.gamma\": gamma,\n",
    "        \"optimization.focal_loss.reduction\": \"sum\",\n",
    "        \"model.timm_image.checkpoint_name\": model_checkpoint,\n",
    "        \"optimization.optim_type\": \"adamw\",\n",
    "        \"optimization.top_k_average_method\": \"best\",\n",
    "    }\n",
    "\n",
    "    # Train model\n",
    "    predictor = MultiModalPredictor(\n",
    "        label=\"label_text\",\n",
    "        path=model_path,\n",
    "        problem_type=\"multiclass\",\n",
    "        eval_metric=\"f1_macro\",\n",
    "    )\n",
    "    predictor.fit(train_data=train_df, hyperparameters=hyperparameters)\n",
    "\n",
    "    # Evaluate model on train_df\n",
    "    train_scores = predictor.evaluate(train_df, metrics=[\"f1_macro\", \"f1_micro\", \"accuracy\", \"recall_macro\", \"precision_macro\"])\n",
    "    \n",
    "    # Evaluate model on test_df\n",
    "    test_scores = predictor.evaluate(test_df, metrics=[\"f1_macro\", \"f1_micro\", \"accuracy\", \"recall_macro\", \"precision_macro\"])\n",
    "\n",
    "    # Print train scores\n",
    "    print(f\"Model {model_name} (hyperparameters {idx}) train scores:\")\n",
    "    for metric, score in train_scores.items():\n",
    "        print(f\"  {metric}: {score}\")\n",
    "\n",
    "    # Print test scores\n",
    "    print(f\"Model {model_name} (hyperparameters {idx}) test scores:\")\n",
    "    for metric, score in test_scores.items():\n",
    "        print(f\"  {metric}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.11.10\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          32\n",
      "Pytorch Version:    2.4.1\n",
      "CUDA Version:       12.4\n",
      "Memory Avail:       111.38 GB / 127.91 GB (87.1%)\n",
      "Disk Space Avail:   1393.77 GB / 1863.00 GB (74.8%)\n",
      "===================================================\n",
      "\n",
      "AutoMM starts to create your model. âœ¨âœ¨âœ¨\n",
      "\n",
      "To track the learning progress, you can open a terminal and launch Tensorboard:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir e:\\Current_Workdir\\palm-fruit-classification\\autogluon_ver\\model\\master\\train_EfficientNet_1_2024-12-30_22-18-48\n",
      "    ```\n",
      "\n",
      "Seed set to 0\n",
      "GPU Count: 1\n",
      "GPU Count to be Used: 1\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------\n",
      "0 | model             | TimmAutoModelForImagePrediction | 7.7 M  | train\n",
      "1 | validation_metric | MulticlassF1Score               | 0      | train\n",
      "2 | loss_func         | FocalLoss                       | 0      | train\n",
      "------------------------------------------------------------------------------\n",
      "7.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.7 M     Total params\n",
      "30.838    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:12<00:13, 10.32it/s]                 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 67: 'val_f1_macro' reached 0.37721 (best 0.37721), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_1_2024-12-30_22-18-48\\\\epoch=0-step=67.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:25<00:00, 10.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 134: 'val_f1_macro' reached 0.61362 (best 0.61362), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_1_2024-12-30_22-18-48\\\\epoch=0-step=134.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:11<00:12, 11.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 202: 'val_f1_macro' reached 0.76387 (best 0.76387), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_1_2024-12-30_22-18-48\\\\epoch=1-step=202.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:24<00:00, 10.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 269: 'val_f1_macro' reached 0.79030 (best 0.79030), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_1_2024-12-30_22-18-48\\\\epoch=1-step=269.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:11<00:12, 11.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 337: 'val_f1_macro' reached 0.80583 (best 0.80583), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_1_2024-12-30_22-18-48\\\\epoch=2-step=337.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:24<00:00, 10.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 404: 'val_f1_macro' reached 0.90214 (best 0.90214), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_1_2024-12-30_22-18-48\\\\epoch=2-step=404.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:12<00:12, 11.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 472: 'val_f1_macro' reached 0.90460 (best 0.90460), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_1_2024-12-30_22-18-48\\\\epoch=3-step=472.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:25<00:00, 10.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 539: 'val_f1_macro' reached 0.91101 (best 0.91101), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_1_2024-12-30_22-18-48\\\\epoch=3-step=539.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:12<00:12, 10.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 607: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:27<00:00,  9.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 674: 'val_f1_macro' reached 0.96761 (best 0.96761), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_1_2024-12-30_22-18-48\\\\epoch=4-step=674.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:13<00:13, 10.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 742: 'val_f1_macro' reached 0.93391 (best 0.96761), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_1_2024-12-30_22-18-48\\\\epoch=5-step=742.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:28<00:00,  9.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 809: 'val_f1_macro' reached 0.96735 (best 0.96761), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_1_2024-12-30_22-18-48\\\\epoch=5-step=809.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:13<00:13, 10.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 877: 'val_f1_macro' reached 0.97092 (best 0.97092), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_1_2024-12-30_22-18-48\\\\epoch=6-step=877.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:27<00:00,  9.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 944: 'val_f1_macro' reached 0.97789 (best 0.97789), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_1_2024-12-30_22-18-48\\\\epoch=6-step=944.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:12<00:12, 10.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 1012: 'val_f1_macro' reached 0.98579 (best 0.98579), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_1_2024-12-30_22-18-48\\\\epoch=7-step=1012.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:26<00:00, 10.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 1079: 'val_f1_macro' reached 0.98546 (best 0.98579), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_1_2024-12-30_22-18-48\\\\epoch=7-step=1079.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:12<00:13, 10.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 1147: 'val_f1_macro' reached 0.98131 (best 0.98579), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_1_2024-12-30_22-18-48\\\\epoch=8-step=1147.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:26<00:00, 10.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 1214: 'val_f1_macro' reached 0.99289 (best 0.99289), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_1_2024-12-30_22-18-48\\\\epoch=8-step=1214.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:12<00:12, 10.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 1282: 'val_f1_macro' reached 0.99001 (best 0.99289), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_1_2024-12-30_22-18-48\\\\epoch=9-step=1282.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:25<00:00, 10.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 1349: 'val_f1_macro' reached 0.99356 (best 0.99356), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_1_2024-12-30_22-18-48\\\\epoch=9-step=1349.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:12<00:12, 10.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 1417: 'val_f1_macro' reached 0.99643 (best 0.99643), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_1_2024-12-30_22-18-48\\\\epoch=10-step=1417.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:25<00:00, 10.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 1484: 'val_f1_macro' reached 0.99356 (best 0.99643), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_1_2024-12-30_22-18-48\\\\epoch=10-step=1484.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:12<00:12, 10.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 1552: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:25<00:00, 10.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 1619: 'val_f1_macro' reached 0.99644 (best 0.99644), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_1_2024-12-30_22-18-48\\\\epoch=11-step=1619.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:13<00:13,  9.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 1687: 'val_f1_macro' reached 0.99452 (best 0.99644), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_1_2024-12-30_22-18-48\\\\epoch=12-step=1687.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:27<00:00,  9.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 1754: 'val_f1_macro' reached 0.99548 (best 0.99644), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_1_2024-12-30_22-18-48\\\\epoch=12-step=1754.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 269/269 [00:28<00:00,  9.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=13` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 269/269 [00:28<00:00,  9.55it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\autogluon\\multimodal\\utils\\checkpoint.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  avg_state_dict = torch.load(checkpoint_paths[0], map_location=torch.device(\"cpu\"))[\"state_dict\"]\n",
      "AutoMM has created your model. ðŸŽ‰ðŸŽ‰ðŸŽ‰\n",
      "\n",
      "To load the model, use the code below:\n",
      "    ```python\n",
      "    from autogluon.multimodal import MultiModalPredictor\n",
      "    predictor = MultiModalPredictor.load(\"e:\\Current_Workdir\\palm-fruit-classification\\autogluon_ver\\model\\master\\train_EfficientNet_1_2024-12-30_22-18-48\")\n",
      "    ```\n",
      "\n",
      "If you are not satisfied with the model, try to increase the training time, \n",
      "adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\n",
      "or post issues on GitHub (https://github.com/autogluon/autogluon/issues).\n",
      "\n",
      "\n",
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83/83 [00:03<00:00, 22.86it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:00<00:00, 18.55it/s]\n",
      "Model EfficientNet (hyperparameters 1) train scores:\n",
      "  f1_macro: 0.9993290633412034\n",
      "  f1_micro: 0.9988674971687429\n",
      "  accuracy: 0.9988674971687429\n",
      "  recall_macro: 0.9994979919678716\n",
      "  precision_macro: 0.9991619526503248\n",
      "Model EfficientNet (hyperparameters 1) test scores:\n",
      "  f1_macro: 0.884675895678717\n",
      "  f1_micro: 0.8601583113456465\n",
      "  accuracy: 0.8601583113456465\n",
      "  recall_macro: 0.8930941039636693\n",
      "  precision_macro: 0.8787630741398287\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate each model with its respective hyperparameters\n",
    "create_and_train_model(hyperparam_1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.11.10\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          32\n",
      "Pytorch Version:    2.4.1\n",
      "CUDA Version:       12.4\n",
      "Memory Avail:       110.03 GB / 127.91 GB (86.0%)\n",
      "Disk Space Avail:   1393.74 GB / 1863.00 GB (74.8%)\n",
      "===================================================\n",
      "\n",
      "AutoMM starts to create your model. âœ¨âœ¨âœ¨\n",
      "\n",
      "To track the learning progress, you can open a terminal and launch Tensorboard:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir e:\\Current_Workdir\\palm-fruit-classification\\autogluon_ver\\model\\master\\train_EfficientNet_2_2024-12-30_22-25-46\n",
      "    ```\n",
      "\n",
      "Seed set to 0\n",
      "GPU Count: 1\n",
      "GPU Count to be Used: 1\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------\n",
      "0 | model             | TimmAutoModelForImagePrediction | 7.7 M  | train\n",
      "1 | validation_metric | MulticlassF1Score               | 0      | train\n",
      "2 | loss_func         | FocalLoss                       | 0      | train\n",
      "------------------------------------------------------------------------------\n",
      "7.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.7 M     Total params\n",
      "30.838    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:12<00:12, 11.05it/s]                 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 8: 'val_f1_macro' reached 0.22420 (best 0.22420), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_2_2024-12-30_22-25-46\\\\epoch=0-step=8.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:25<00:00, 10.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 16: 'val_f1_macro' reached 0.43901 (best 0.43901), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_2_2024-12-30_22-25-46\\\\epoch=0-step=16.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:12<00:12, 10.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 25: 'val_f1_macro' reached 0.54341 (best 0.54341), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_2_2024-12-30_22-25-46\\\\epoch=1-step=25.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:25<00:00, 10.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 33: 'val_f1_macro' reached 0.68100 (best 0.68100), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_2_2024-12-30_22-25-46\\\\epoch=1-step=33.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:12<00:12, 11.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 42: 'val_f1_macro' reached 0.72622 (best 0.72622), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_2_2024-12-30_22-25-46\\\\epoch=2-step=42.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:25<00:00, 10.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 50: 'val_f1_macro' reached 0.74945 (best 0.74945), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_2_2024-12-30_22-25-46\\\\epoch=2-step=50.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:12<00:12, 11.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 59: 'val_f1_macro' reached 0.74432 (best 0.74945), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_2_2024-12-30_22-25-46\\\\epoch=3-step=59.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:24<00:00, 10.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 67: 'val_f1_macro' reached 0.75709 (best 0.75709), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_2_2024-12-30_22-25-46\\\\epoch=3-step=67.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:12<00:12, 10.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 76: 'val_f1_macro' reached 0.76906 (best 0.76906), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_2_2024-12-30_22-25-46\\\\epoch=4-step=76.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:25<00:00, 10.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 84: 'val_f1_macro' reached 0.77609 (best 0.77609), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_2_2024-12-30_22-25-46\\\\epoch=4-step=84.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:13<00:13,  9.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 93: 'val_f1_macro' reached 0.79734 (best 0.79734), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_2_2024-12-30_22-25-46\\\\epoch=5-step=93.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:27<00:00,  9.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 101: 'val_f1_macro' reached 0.79365 (best 0.79734), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_2_2024-12-30_22-25-46\\\\epoch=5-step=101.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:12<00:12, 10.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 110: 'val_f1_macro' reached 0.79554 (best 0.79734), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_2_2024-12-30_22-25-46\\\\epoch=6-step=110.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:25<00:00, 10.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 118: 'val_f1_macro' reached 0.81728 (best 0.81728), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_2_2024-12-30_22-25-46\\\\epoch=6-step=118.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 269/269 [00:26<00:00, 10.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=7` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 269/269 [00:26<00:00, 10.12it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\autogluon\\multimodal\\utils\\checkpoint.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  avg_state_dict = torch.load(checkpoint_paths[0], map_location=torch.device(\"cpu\"))[\"state_dict\"]\n",
      "AutoMM has created your model. ðŸŽ‰ðŸŽ‰ðŸŽ‰\n",
      "\n",
      "To load the model, use the code below:\n",
      "    ```python\n",
      "    from autogluon.multimodal import MultiModalPredictor\n",
      "    predictor = MultiModalPredictor.load(\"e:\\Current_Workdir\\palm-fruit-classification\\autogluon_ver\\model\\master\\train_EfficientNet_2_2024-12-30_22-25-46\")\n",
      "    ```\n",
      "\n",
      "If you are not satisfied with the model, try to increase the training time, \n",
      "adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\n",
      "or post issues on GitHub (https://github.com/autogluon/autogluon/issues).\n",
      "\n",
      "\n",
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83/83 [00:03<00:00, 22.55it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:00<00:00, 16.51it/s]\n",
      "Model EfficientNet (hyperparameters 2) train scores:\n",
      "  f1_macro: 0.8794564785000265\n",
      "  f1_micro: 0.8501321253303133\n",
      "  accuracy: 0.8501321253303133\n",
      "  recall_macro: 0.9149967358260773\n",
      "  precision_macro: 0.8522810365755951\n",
      "Model EfficientNet (hyperparameters 2) test scores:\n",
      "  f1_macro: 0.6594713740823798\n",
      "  f1_micro: 0.683377308707124\n",
      "  accuracy: 0.683377308707124\n",
      "  recall_macro: 0.6663304422362394\n",
      "  precision_macro: 0.6887716450216451\n"
     ]
    }
   ],
   "source": [
    "create_and_train_model(hyperparam_2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.11.10\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          32\n",
      "Pytorch Version:    2.4.1\n",
      "CUDA Version:       12.4\n",
      "Memory Avail:       110.18 GB / 127.91 GB (86.1%)\n",
      "Disk Space Avail:   1393.72 GB / 1863.00 GB (74.8%)\n",
      "===================================================\n",
      "\n",
      "AutoMM starts to create your model. âœ¨âœ¨âœ¨\n",
      "\n",
      "To track the learning progress, you can open a terminal and launch Tensorboard:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir e:\\Current_Workdir\\palm-fruit-classification\\autogluon_ver\\model\\master\\train_EfficientNet_3_2024-12-30_22-29-55\n",
      "    ```\n",
      "\n",
      "Seed set to 0\n",
      "GPU Count: 1\n",
      "GPU Count to be Used: 1\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------\n",
      "0 | model             | TimmAutoModelForImagePrediction | 7.7 M  | train\n",
      "1 | validation_metric | MulticlassF1Score               | 0      | train\n",
      "2 | loss_func         | FocalLoss                       | 0      | train\n",
      "------------------------------------------------------------------------------\n",
      "7.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.7 M     Total params\n",
      "30.838    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:12<00:12, 10.55it/s]                 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 67: 'val_f1_macro' reached 0.48908 (best 0.48908), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_3_2024-12-30_22-29-55\\\\epoch=0-step=67.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:26<00:00, 10.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 134: 'val_f1_macro' reached 0.54968 (best 0.54968), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_3_2024-12-30_22-29-55\\\\epoch=0-step=134.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:12<00:13, 10.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 202: 'val_f1_macro' reached 0.73882 (best 0.73882), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_3_2024-12-30_22-29-55\\\\epoch=1-step=202.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:26<00:00,  9.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 269: 'val_f1_macro' reached 0.86535 (best 0.86535), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_3_2024-12-30_22-29-55\\\\epoch=1-step=269.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:12<00:12, 10.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 337: 'val_f1_macro' reached 0.87957 (best 0.87957), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_3_2024-12-30_22-29-55\\\\epoch=2-step=337.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:26<00:00, 10.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 404: 'val_f1_macro' reached 0.91064 (best 0.91064), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_3_2024-12-30_22-29-55\\\\epoch=2-step=404.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:12<00:12, 10.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 472: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:25<00:00, 10.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 539: 'val_f1_macro' reached 0.96033 (best 0.96033), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_3_2024-12-30_22-29-55\\\\epoch=3-step=539.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:11<00:11, 11.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 607: 'val_f1_macro' reached 0.93412 (best 0.96033), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_3_2024-12-30_22-29-55\\\\epoch=4-step=607.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:26<00:00, 10.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 674: 'val_f1_macro' reached 0.97813 (best 0.97813), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_3_2024-12-30_22-29-55\\\\epoch=4-step=674.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:13<00:13, 10.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 742: 'val_f1_macro' reached 0.97077 (best 0.97813), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_3_2024-12-30_22-29-55\\\\epoch=5-step=742.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:28<00:00,  9.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 809: 'val_f1_macro' reached 0.98840 (best 0.98840), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_3_2024-12-30_22-29-55\\\\epoch=5-step=809.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:12<00:12, 10.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 877: 'val_f1_macro' reached 0.98979 (best 0.98979), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_3_2024-12-30_22-29-55\\\\epoch=6-step=877.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:27<00:00,  9.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 944: 'val_f1_macro' reached 0.98908 (best 0.98979), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_3_2024-12-30_22-29-55\\\\epoch=6-step=944.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:12<00:12, 10.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 1012: 'val_f1_macro' reached 0.99099 (best 0.99099), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_3_2024-12-30_22-29-55\\\\epoch=7-step=1012.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:26<00:00, 10.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 1079: 'val_f1_macro' reached 0.99264 (best 0.99264), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNet_3_2024-12-30_22-29-55\\\\epoch=7-step=1079.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 269/269 [00:27<00:00,  9.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=8` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 269/269 [00:27<00:00,  9.83it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\autogluon\\multimodal\\utils\\checkpoint.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  avg_state_dict = torch.load(checkpoint_paths[0], map_location=torch.device(\"cpu\"))[\"state_dict\"]\n",
      "AutoMM has created your model. ðŸŽ‰ðŸŽ‰ðŸŽ‰\n",
      "\n",
      "To load the model, use the code below:\n",
      "    ```python\n",
      "    from autogluon.multimodal import MultiModalPredictor\n",
      "    predictor = MultiModalPredictor.load(\"e:\\Current_Workdir\\palm-fruit-classification\\autogluon_ver\\model\\master\\train_EfficientNet_3_2024-12-30_22-29-55\")\n",
      "    ```\n",
      "\n",
      "If you are not satisfied with the model, try to increase the training time, \n",
      "adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\n",
      "or post issues on GitHub (https://github.com/autogluon/autogluon/issues).\n",
      "\n",
      "\n",
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83/83 [00:03<00:00, 22.58it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:00<00:00, 17.60it/s]\n",
      "Model EfficientNet (hyperparameters 3) train scores:\n",
      "  f1_macro: 0.9984310589738629\n",
      "  f1_micro: 0.9977349943374858\n",
      "  accuracy: 0.9977349943374858\n",
      "  recall_macro: 0.9980295330983798\n",
      "  precision_macro: 0.9988425925925926\n",
      "Model EfficientNet (hyperparameters 3) test scores:\n",
      "  f1_macro: 0.9129994797072648\n",
      "  f1_micro: 0.9023746701846965\n",
      "  accuracy: 0.9023746701846965\n",
      "  recall_macro: 0.8992751143113463\n",
      "  precision_macro: 0.9284803696035581\n"
     ]
    }
   ],
   "source": [
    "create_and_train_model(hyperparam_3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.11.10\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          32\n",
      "Pytorch Version:    2.4.1\n",
      "CUDA Version:       12.4\n",
      "Memory Avail:       110.02 GB / 127.91 GB (86.0%)\n",
      "Disk Space Avail:   1393.69 GB / 1863.00 GB (74.8%)\n",
      "===================================================\n",
      "\n",
      "AutoMM starts to create your model. âœ¨âœ¨âœ¨\n",
      "\n",
      "To track the learning progress, you can open a terminal and launch Tensorboard:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir e:\\Current_Workdir\\palm-fruit-classification\\autogluon_ver\\model\\master\\train_ResNet18_4_2024-12-30_22-34-38\n",
      "    ```\n",
      "\n",
      "Seed set to 0\n",
      "GPU Count: 1\n",
      "GPU Count to be Used: 1\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------\n",
      "0 | model             | TimmAutoModelForImagePrediction | 11.2 M | train\n",
      "1 | validation_metric | MulticlassF1Score               | 0      | train\n",
      "2 | loss_func         | FocalLoss                       | 0      | train\n",
      "------------------------------------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.718    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 29.75it/s]                 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 134: 'val_f1_macro' reached 0.38448 (best 0.38448), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_4_2024-12-30_22-34-38\\\\epoch=0-step=134.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:09<00:00, 27.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 268: 'val_f1_macro' reached 0.62221 (best 0.62221), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_4_2024-12-30_22-34-38\\\\epoch=0-step=268.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 32.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 403: 'val_f1_macro' reached 0.78362 (best 0.78362), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_4_2024-12-30_22-34-38\\\\epoch=1-step=403.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:09<00:00, 28.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 537: 'val_f1_macro' reached 0.86440 (best 0.86440), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_4_2024-12-30_22-34-38\\\\epoch=1-step=537.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 31.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 672: 'val_f1_macro' reached 0.86248 (best 0.86440), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_4_2024-12-30_22-34-38\\\\epoch=2-step=672.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:09<00:00, 27.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 806: 'val_f1_macro' reached 0.88763 (best 0.88763), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_4_2024-12-30_22-34-38\\\\epoch=2-step=806.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 32.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 941: 'val_f1_macro' reached 0.89485 (best 0.89485), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_4_2024-12-30_22-34-38\\\\epoch=3-step=941.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:09<00:00, 28.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 1075: 'val_f1_macro' reached 0.91662 (best 0.91662), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_4_2024-12-30_22-34-38\\\\epoch=3-step=1075.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 32.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 1210: 'val_f1_macro' reached 0.92475 (best 0.92475), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_4_2024-12-30_22-34-38\\\\epoch=4-step=1210.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:09<00:00, 28.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 1344: 'val_f1_macro' reached 0.94990 (best 0.94990), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_4_2024-12-30_22-34-38\\\\epoch=4-step=1344.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 30.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 1479: 'val_f1_macro' reached 0.95035 (best 0.95035), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_4_2024-12-30_22-34-38\\\\epoch=5-step=1479.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:09<00:00, 27.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 1613: 'val_f1_macro' reached 0.95689 (best 0.95689), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_4_2024-12-30_22-34-38\\\\epoch=5-step=1613.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 32.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 1748: 'val_f1_macro' reached 0.95330 (best 0.95689), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_4_2024-12-30_22-34-38\\\\epoch=6-step=1748.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:09<00:00, 28.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 1882: 'val_f1_macro' reached 0.96312 (best 0.96312), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_4_2024-12-30_22-34-38\\\\epoch=6-step=1882.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 32.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 2017: 'val_f1_macro' reached 0.95774 (best 0.96312), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_4_2024-12-30_22-34-38\\\\epoch=7-step=2017.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:09<00:00, 28.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 2151: 'val_f1_macro' reached 0.96086 (best 0.96312), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_4_2024-12-30_22-34-38\\\\epoch=7-step=2151.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 31.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 2286: 'val_f1_macro' reached 0.97210 (best 0.97210), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_4_2024-12-30_22-34-38\\\\epoch=8-step=2286.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:09<00:00, 28.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 2420: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 269/269 [00:10<00:00, 26.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=9` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 269/269 [00:10<00:00, 26.65it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\autogluon\\multimodal\\utils\\checkpoint.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  avg_state_dict = torch.load(checkpoint_paths[0], map_location=torch.device(\"cpu\"))[\"state_dict\"]\n",
      "AutoMM has created your model. ðŸŽ‰ðŸŽ‰ðŸŽ‰\n",
      "\n",
      "To load the model, use the code below:\n",
      "    ```python\n",
      "    from autogluon.multimodal import MultiModalPredictor\n",
      "    predictor = MultiModalPredictor.load(\"e:\\Current_Workdir\\palm-fruit-classification\\autogluon_ver\\model\\master\\train_ResNet18_4_2024-12-30_22-34-38\")\n",
      "    ```\n",
      "\n",
      "If you are not satisfied with the model, try to increase the training time, \n",
      "adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\n",
      "or post issues on GitHub (https://github.com/autogluon/autogluon/issues).\n",
      "\n",
      "\n",
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83/83 [00:02<00:00, 38.45it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:00<00:00, 22.47it/s]\n",
      "Model ResNet18 (hyperparameters 4) train scores:\n",
      "  f1_macro: 0.9943624300623473\n",
      "  f1_micro: 0.9913174782936958\n",
      "  accuracy: 0.9913174782936958\n",
      "  recall_macro: 0.9947390006424053\n",
      "  precision_macro: 0.9940005160754275\n",
      "Model ResNet18 (hyperparameters 4) test scores:\n",
      "  f1_macro: 0.8880079676576389\n",
      "  f1_micro: 0.8680738786279684\n",
      "  accuracy: 0.8680738786279684\n",
      "  recall_macro: 0.8991442266804586\n",
      "  precision_macro: 0.8787819700031311\n"
     ]
    }
   ],
   "source": [
    "create_and_train_model(hyperparam_4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.11.10\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          32\n",
      "Pytorch Version:    2.4.1\n",
      "CUDA Version:       12.4\n",
      "Memory Avail:       109.79 GB / 127.91 GB (85.8%)\n",
      "Disk Space Avail:   1393.65 GB / 1863.00 GB (74.8%)\n",
      "===================================================\n",
      "\n",
      "AutoMM starts to create your model. âœ¨âœ¨âœ¨\n",
      "\n",
      "To track the learning progress, you can open a terminal and launch Tensorboard:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir e:\\Current_Workdir\\palm-fruit-classification\\autogluon_ver\\model\\master\\train_ResNet18_5_2024-12-30_22-37-13\n",
      "    ```\n",
      "\n",
      "Seed set to 0\n",
      "GPU Count: 1\n",
      "GPU Count to be Used: 1\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------\n",
      "0 | model             | TimmAutoModelForImagePrediction | 11.2 M | train\n",
      "1 | validation_metric | MulticlassF1Score               | 0      | train\n",
      "2 | loss_func         | FocalLoss                       | 0      | train\n",
      "------------------------------------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.718    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:03<00:03, 39.20it/s]                 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 4: 'val_f1_macro' reached 0.13291 (best 0.13291), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_5_2024-12-30_22-37-13\\\\epoch=0-step=4.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:07<00:00, 34.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 8: 'val_f1_macro' reached 0.17638 (best 0.17638), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_5_2024-12-30_22-37-13\\\\epoch=0-step=8.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:03<00:03, 38.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 13: 'val_f1_macro' reached 0.29253 (best 0.29253), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_5_2024-12-30_22-37-13\\\\epoch=1-step=13.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:08<00:00, 33.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 17: 'val_f1_macro' reached 0.32774 (best 0.32774), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_5_2024-12-30_22-37-13\\\\epoch=1-step=17.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:03<00:03, 37.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 22: 'val_f1_macro' reached 0.42085 (best 0.42085), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_5_2024-12-30_22-37-13\\\\epoch=2-step=22.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:08<00:00, 33.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 26: 'val_f1_macro' reached 0.46798 (best 0.46798), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_5_2024-12-30_22-37-13\\\\epoch=2-step=26.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:03<00:03, 38.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 31: 'val_f1_macro' reached 0.41978 (best 0.46798), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_5_2024-12-30_22-37-13\\\\epoch=3-step=31.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:07<00:00, 34.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 35: 'val_f1_macro' reached 0.46539 (best 0.46798), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_5_2024-12-30_22-37-13\\\\epoch=3-step=35.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:03<00:03, 39.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 40: 'val_f1_macro' reached 0.48742 (best 0.48742), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_5_2024-12-30_22-37-13\\\\epoch=4-step=40.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:07<00:00, 35.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 44: 'val_f1_macro' reached 0.49498 (best 0.49498), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_5_2024-12-30_22-37-13\\\\epoch=4-step=44.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:03<00:03, 40.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 49: 'val_f1_macro' reached 0.50390 (best 0.50390), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_5_2024-12-30_22-37-13\\\\epoch=5-step=49.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:07<00:00, 34.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 53: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:03<00:03, 41.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 58: 'val_f1_macro' reached 0.49778 (best 0.50390), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_5_2024-12-30_22-37-13\\\\epoch=6-step=58.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:07<00:00, 35.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 62: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 269/269 [00:08<00:00, 32.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=7` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 269/269 [00:08<00:00, 32.76it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\autogluon\\multimodal\\utils\\checkpoint.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  avg_state_dict = torch.load(checkpoint_paths[0], map_location=torch.device(\"cpu\"))[\"state_dict\"]\n",
      "AutoMM has created your model. ðŸŽ‰ðŸŽ‰ðŸŽ‰\n",
      "\n",
      "To load the model, use the code below:\n",
      "    ```python\n",
      "    from autogluon.multimodal import MultiModalPredictor\n",
      "    predictor = MultiModalPredictor.load(\"e:\\Current_Workdir\\palm-fruit-classification\\autogluon_ver\\model\\master\\train_ResNet18_5_2024-12-30_22-37-13\")\n",
      "    ```\n",
      "\n",
      "If you are not satisfied with the model, try to increase the training time, \n",
      "adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\n",
      "or post issues on GitHub (https://github.com/autogluon/autogluon/issues).\n",
      "\n",
      "\n",
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83/83 [00:02<00:00, 38.30it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:00<00:00, 24.00it/s]\n",
      "Model ResNet18 (hyperparameters 5) train scores:\n",
      "  f1_macro: 0.5503866838143608\n",
      "  f1_micro: 0.5285013212533032\n",
      "  accuracy: 0.5285013212533032\n",
      "  recall_macro: 0.6999065965043245\n",
      "  precision_macro: 0.5365350870934883\n",
      "Model ResNet18 (hyperparameters 5) test scores:\n",
      "  f1_macro: 0.4482421317722825\n",
      "  f1_micro: 0.46174142480211083\n",
      "  accuracy: 0.46174142480211083\n",
      "  recall_macro: 0.5622070964462268\n",
      "  precision_macro: 0.4694522971684258\n"
     ]
    }
   ],
   "source": [
    "create_and_train_model(hyperparam_5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.11.10\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          32\n",
      "Pytorch Version:    2.4.1\n",
      "CUDA Version:       12.4\n",
      "Memory Avail:       109.63 GB / 127.91 GB (85.7%)\n",
      "Disk Space Avail:   1393.60 GB / 1863.00 GB (74.8%)\n",
      "===================================================\n",
      "\n",
      "AutoMM starts to create your model. âœ¨âœ¨âœ¨\n",
      "\n",
      "To track the learning progress, you can open a terminal and launch Tensorboard:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir e:\\Current_Workdir\\palm-fruit-classification\\autogluon_ver\\model\\master\\train_ResNet18_6_2024-12-30_22-39-14\n",
      "    ```\n",
      "\n",
      "Seed set to 0\n",
      "GPU Count: 1\n",
      "GPU Count to be Used: 1\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------\n",
      "0 | model             | TimmAutoModelForImagePrediction | 11.2 M | train\n",
      "1 | validation_metric | MulticlassF1Score               | 0      | train\n",
      "2 | loss_func         | FocalLoss                       | 0      | train\n",
      "------------------------------------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.718    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 30.72it/s]                 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 134: 'val_f1_macro' reached 0.38905 (best 0.38905), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_6_2024-12-30_22-39-14\\\\epoch=0-step=134.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:09<00:00, 27.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 268: 'val_f1_macro' reached 0.63428 (best 0.63428), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_6_2024-12-30_22-39-14\\\\epoch=0-step=268.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 30.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 403: 'val_f1_macro' reached 0.79997 (best 0.79997), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_6_2024-12-30_22-39-14\\\\epoch=1-step=403.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:09<00:00, 27.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 537: 'val_f1_macro' reached 0.82060 (best 0.82060), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_6_2024-12-30_22-39-14\\\\epoch=1-step=537.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 31.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 672: 'val_f1_macro' reached 0.86931 (best 0.86931), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_6_2024-12-30_22-39-14\\\\epoch=2-step=672.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:09<00:00, 28.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 806: 'val_f1_macro' reached 0.88511 (best 0.88511), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_6_2024-12-30_22-39-14\\\\epoch=2-step=806.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 32.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 941: 'val_f1_macro' reached 0.91969 (best 0.91969), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_6_2024-12-30_22-39-14\\\\epoch=3-step=941.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:09<00:00, 27.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 1075: 'val_f1_macro' reached 0.89026 (best 0.91969), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_6_2024-12-30_22-39-14\\\\epoch=3-step=1075.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 30.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 1210: 'val_f1_macro' reached 0.95078 (best 0.95078), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_6_2024-12-30_22-39-14\\\\epoch=4-step=1210.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:09<00:00, 27.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 1344: 'val_f1_macro' reached 0.94104 (best 0.95078), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_6_2024-12-30_22-39-14\\\\epoch=4-step=1344.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 32.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 1479: 'val_f1_macro' reached 0.94379 (best 0.95078), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_6_2024-12-30_22-39-14\\\\epoch=5-step=1479.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:09<00:00, 28.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 1613: 'val_f1_macro' reached 0.95457 (best 0.95457), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_6_2024-12-30_22-39-14\\\\epoch=5-step=1613.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 31.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 1748: 'val_f1_macro' reached 0.96070 (best 0.96070), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_6_2024-12-30_22-39-14\\\\epoch=6-step=1748.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:09<00:00, 27.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 1882: 'val_f1_macro' reached 0.96284 (best 0.96284), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_6_2024-12-30_22-39-14\\\\epoch=6-step=1882.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 31.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 2017: 'val_f1_macro' reached 0.96908 (best 0.96908), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_6_2024-12-30_22-39-14\\\\epoch=7-step=2017.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:09<00:00, 28.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 2151: 'val_f1_macro' reached 0.96902 (best 0.96908), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_6_2024-12-30_22-39-14\\\\epoch=7-step=2151.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 32.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 2286: 'val_f1_macro' reached 0.97459 (best 0.97459), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_ResNet18_6_2024-12-30_22-39-14\\\\epoch=8-step=2286.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:09<00:00, 28.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 2420: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 269/269 [00:09<00:00, 27.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=9` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 269/269 [00:09<00:00, 27.10it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\autogluon\\multimodal\\utils\\checkpoint.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  avg_state_dict = torch.load(checkpoint_paths[0], map_location=torch.device(\"cpu\"))[\"state_dict\"]\n",
      "AutoMM has created your model. ðŸŽ‰ðŸŽ‰ðŸŽ‰\n",
      "\n",
      "To load the model, use the code below:\n",
      "    ```python\n",
      "    from autogluon.multimodal import MultiModalPredictor\n",
      "    predictor = MultiModalPredictor.load(\"e:\\Current_Workdir\\palm-fruit-classification\\autogluon_ver\\model\\master\\train_ResNet18_6_2024-12-30_22-39-14\")\n",
      "    ```\n",
      "\n",
      "If you are not satisfied with the model, try to increase the training time, \n",
      "adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\n",
      "or post issues on GitHub (https://github.com/autogluon/autogluon/issues).\n",
      "\n",
      "\n",
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83/83 [00:02<00:00, 37.15it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:00<00:00, 21.09it/s]\n",
      "Model ResNet18 (hyperparameters 6) train scores:\n",
      "  f1_macro: 0.9948089610154413\n",
      "  f1_micro: 0.9924499811249529\n",
      "  accuracy: 0.9924499811249529\n",
      "  recall_macro: 0.9962074595118967\n",
      "  precision_macro: 0.9934341292480008\n",
      "Model ResNet18 (hyperparameters 6) test scores:\n",
      "  f1_macro: 0.8943761645448456\n",
      "  f1_micro: 0.8891820580474934\n",
      "  accuracy: 0.8891820580474934\n",
      "  recall_macro: 0.8978710433420578\n",
      "  precision_macro: 0.8924692562691813\n"
     ]
    }
   ],
   "source": [
    "create_and_train_model(hyperparam_6, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.11.10\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          32\n",
      "Pytorch Version:    2.4.1\n",
      "CUDA Version:       12.4\n",
      "Memory Avail:       109.90 GB / 127.91 GB (85.9%)\n",
      "Disk Space Avail:   1393.56 GB / 1863.00 GB (74.8%)\n",
      "===================================================\n",
      "\n",
      "AutoMM starts to create your model. âœ¨âœ¨âœ¨\n",
      "\n",
      "To track the learning progress, you can open a terminal and launch Tensorboard:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir e:\\Current_Workdir\\palm-fruit-classification\\autogluon_ver\\model\\master\\train_EfficientNetv2_7_2024-12-30_22-41-49\n",
      "    ```\n",
      "\n",
      "Seed set to 0\n",
      "GPU Count: 1\n",
      "GPU Count to be Used: 1\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------\n",
      "0 | model             | TimmAutoModelForImagePrediction | 20.2 M | train\n",
      "1 | validation_metric | MulticlassF1Score               | 0      | train\n",
      "2 | loss_func         | FocalLoss                       | 0      | train\n",
      "------------------------------------------------------------------------------\n",
      "20.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "20.2 M    Total params\n",
      "80.741    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:15<00:16,  8.40it/s]                 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 67: 'val_f1_macro' reached 0.65930 (best 0.65930), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_7_2024-12-30_22-41-49\\\\epoch=0-step=67.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:33<00:00,  7.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 134: 'val_f1_macro' reached 0.78700 (best 0.78700), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_7_2024-12-30_22-41-49\\\\epoch=0-step=134.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:15<00:15,  8.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 202: 'val_f1_macro' reached 0.84111 (best 0.84111), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_7_2024-12-30_22-41-49\\\\epoch=1-step=202.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:33<00:00,  8.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 269: 'val_f1_macro' reached 0.90239 (best 0.90239), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_7_2024-12-30_22-41-49\\\\epoch=1-step=269.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:15<00:15,  8.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 337: 'val_f1_macro' reached 0.91831 (best 0.91831), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_7_2024-12-30_22-41-49\\\\epoch=2-step=337.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:33<00:00,  8.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 404: 'val_f1_macro' reached 0.97660 (best 0.97660), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_7_2024-12-30_22-41-49\\\\epoch=2-step=404.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:15<00:15,  8.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 472: 'val_f1_macro' reached 0.97142 (best 0.97660), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_7_2024-12-30_22-41-49\\\\epoch=3-step=472.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:33<00:00,  8.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 539: 'val_f1_macro' reached 0.98655 (best 0.98655), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_7_2024-12-30_22-41-49\\\\epoch=3-step=539.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:15<00:15,  8.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 607: 'val_f1_macro' reached 0.98181 (best 0.98655), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_7_2024-12-30_22-41-49\\\\epoch=4-step=607.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:33<00:00,  7.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 674: 'val_f1_macro' reached 0.99140 (best 0.99140), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_7_2024-12-30_22-41-49\\\\epoch=4-step=674.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:15<00:15,  8.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 742: 'val_f1_macro' reached 0.99713 (best 0.99713), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_7_2024-12-30_22-41-49\\\\epoch=5-step=742.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:33<00:00,  8.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 809: 'val_f1_macro' reached 0.99522 (best 0.99713), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_7_2024-12-30_22-41-49\\\\epoch=5-step=809.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:15<00:15,  8.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 877: 'val_f1_macro' reached 0.99617 (best 0.99713), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_7_2024-12-30_22-41-49\\\\epoch=6-step=877.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:33<00:00,  8.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 944: 'val_f1_macro' reached 0.99618 (best 0.99713), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_7_2024-12-30_22-41-49\\\\epoch=6-step=944.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 269/269 [00:35<00:00,  7.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=7` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 269/269 [00:35<00:00,  7.51it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\autogluon\\multimodal\\utils\\checkpoint.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  avg_state_dict = torch.load(checkpoint_paths[0], map_location=torch.device(\"cpu\"))[\"state_dict\"]\n",
      "AutoMM has created your model. ðŸŽ‰ðŸŽ‰ðŸŽ‰\n",
      "\n",
      "To load the model, use the code below:\n",
      "    ```python\n",
      "    from autogluon.multimodal import MultiModalPredictor\n",
      "    predictor = MultiModalPredictor.load(\"e:\\Current_Workdir\\palm-fruit-classification\\autogluon_ver\\model\\master\\train_EfficientNetv2_7_2024-12-30_22-41-49\")\n",
      "    ```\n",
      "\n",
      "If you are not satisfied with the model, try to increase the training time, \n",
      "adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\n",
      "or post issues on GitHub (https://github.com/autogluon/autogluon/issues).\n",
      "\n",
      "\n",
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83/83 [00:07<00:00, 11.64it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  9.53it/s]\n",
      "Model EfficientNetv2 (hyperparameters 7) train scores:\n",
      "  f1_macro: 0.9985529389038161\n",
      "  f1_micro: 0.9969799924499811\n",
      "  accuracy: 0.9969799924499811\n",
      "  recall_macro: 0.9984729126295391\n",
      "  precision_macro: 0.9986400438559501\n",
      "Model EfficientNetv2 (hyperparameters 7) test scores:\n",
      "  f1_macro: 0.9002003815330234\n",
      "  f1_micro: 0.8891820580474934\n",
      "  accuracy: 0.8891820580474934\n",
      "  recall_macro: 0.8939114964477283\n",
      "  precision_macro: 0.9101166948993035\n"
     ]
    }
   ],
   "source": [
    "create_and_train_model(hyperparam_7, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.11.10\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          32\n",
      "Pytorch Version:    2.4.1\n",
      "CUDA Version:       12.4\n",
      "Memory Avail:       109.72 GB / 127.91 GB (85.8%)\n",
      "Disk Space Avail:   1393.48 GB / 1863.00 GB (74.8%)\n",
      "===================================================\n",
      "\n",
      "AutoMM starts to create your model. âœ¨âœ¨âœ¨\n",
      "\n",
      "To track the learning progress, you can open a terminal and launch Tensorboard:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir e:\\Current_Workdir\\palm-fruit-classification\\autogluon_ver\\model\\master\\train_EfficientNetv2_8_2024-12-30_22-47-09\n",
      "    ```\n",
      "\n",
      "Seed set to 0\n",
      "GPU Count: 1\n",
      "GPU Count to be Used: 1\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------\n",
      "0 | model             | TimmAutoModelForImagePrediction | 20.2 M | train\n",
      "1 | validation_metric | MulticlassF1Score               | 0      | train\n",
      "2 | loss_func         | FocalLoss                       | 0      | train\n",
      "------------------------------------------------------------------------------\n",
      "20.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "20.2 M    Total params\n",
      "80.741    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:15<00:15,  8.73it/s]                 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 16: 'val_f1_macro' reached 0.31288 (best 0.31288), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_8_2024-12-30_22-47-09\\\\epoch=0-step=16.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:32<00:00,  8.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 33: 'val_f1_macro' reached 0.56787 (best 0.56787), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_8_2024-12-30_22-47-09\\\\epoch=0-step=33.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:15<00:15,  8.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 50: 'val_f1_macro' reached 0.78445 (best 0.78445), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_8_2024-12-30_22-47-09\\\\epoch=1-step=50.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:32<00:00,  8.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 67: 'val_f1_macro' reached 0.86724 (best 0.86724), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_8_2024-12-30_22-47-09\\\\epoch=1-step=67.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:15<00:15,  8.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 84: 'val_f1_macro' reached 0.84514 (best 0.86724), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_8_2024-12-30_22-47-09\\\\epoch=2-step=84.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:32<00:00,  8.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 101: 'val_f1_macro' reached 0.91415 (best 0.91415), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_8_2024-12-30_22-47-09\\\\epoch=2-step=101.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:15<00:15,  8.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 118: 'val_f1_macro' reached 0.94746 (best 0.94746), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_8_2024-12-30_22-47-09\\\\epoch=3-step=118.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:32<00:00,  8.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 135: 'val_f1_macro' reached 0.92725 (best 0.94746), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_8_2024-12-30_22-47-09\\\\epoch=3-step=135.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:15<00:15,  8.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 152: 'val_f1_macro' reached 0.91551 (best 0.94746), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_8_2024-12-30_22-47-09\\\\epoch=4-step=152.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:32<00:00,  8.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 169: 'val_f1_macro' reached 0.94634 (best 0.94746), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_8_2024-12-30_22-47-09\\\\epoch=4-step=169.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:15<00:15,  8.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 186: 'val_f1_macro' reached 0.96154 (best 0.96154), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_8_2024-12-30_22-47-09\\\\epoch=5-step=186.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:32<00:00,  8.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 203: 'val_f1_macro' reached 0.97450 (best 0.97450), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_8_2024-12-30_22-47-09\\\\epoch=5-step=203.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:15<00:15,  8.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 220: 'val_f1_macro' reached 0.96345 (best 0.97450), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_8_2024-12-30_22-47-09\\\\epoch=6-step=220.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:32<00:00,  8.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 237: 'val_f1_macro' reached 0.97540 (best 0.97540), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_8_2024-12-30_22-47-09\\\\epoch=6-step=237.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:14<00:15,  8.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 254: 'val_f1_macro' reached 0.97177 (best 0.97540), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_8_2024-12-30_22-47-09\\\\epoch=7-step=254.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:32<00:00,  8.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 271: 'val_f1_macro' reached 0.98242 (best 0.98242), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_8_2024-12-30_22-47-09\\\\epoch=7-step=271.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:15<00:15,  8.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 288: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:31<00:00,  8.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 305: 'val_f1_macro' reached 0.98466 (best 0.98466), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_8_2024-12-30_22-47-09\\\\epoch=8-step=305.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:15<00:15,  8.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 322: 'val_f1_macro' reached 0.98318 (best 0.98466), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_8_2024-12-30_22-47-09\\\\epoch=9-step=322.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:32<00:00,  8.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 339: 'val_f1_macro' reached 0.98782 (best 0.98782), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_8_2024-12-30_22-47-09\\\\epoch=9-step=339.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:15<00:15,  8.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 356: 'val_f1_macro' reached 0.99126 (best 0.99126), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_8_2024-12-30_22-47-09\\\\epoch=10-step=356.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:32<00:00,  8.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 373: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:15<00:15,  8.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 390: 'val_f1_macro' reached 0.99643 (best 0.99643), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_8_2024-12-30_22-47-09\\\\epoch=11-step=390.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:32<00:00,  8.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 407: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:15<00:15,  8.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 424: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:31<00:00,  8.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 441: 'val_f1_macro' reached 0.99809 (best 0.99809), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_8_2024-12-30_22-47-09\\\\epoch=12-step=441.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:15<00:15,  8.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 458: 'val_f1_macro' reached 0.99808 (best 0.99809), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_8_2024-12-30_22-47-09\\\\epoch=13-step=458.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:32<00:00,  8.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 475: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:15<00:15,  8.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 492: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:31<00:00,  8.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 509: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:15<00:15,  8.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 526: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:31<00:00,  8.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 543: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:15<00:15,  8.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 560: 'val_f1_macro' reached 0.99644 (best 0.99809), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_8_2024-12-30_22-47-09\\\\epoch=16-step=560.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:32<00:00,  8.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 577: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:15<00:15,  8.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 594: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:31<00:00,  8.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 611: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:32<00:00,  8.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=18` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:32<00:00,  8.19it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\autogluon\\multimodal\\utils\\checkpoint.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  avg_state_dict = torch.load(checkpoint_paths[0], map_location=torch.device(\"cpu\"))[\"state_dict\"]\n",
      "AutoMM has created your model. ðŸŽ‰ðŸŽ‰ðŸŽ‰\n",
      "\n",
      "To load the model, use the code below:\n",
      "    ```python\n",
      "    from autogluon.multimodal import MultiModalPredictor\n",
      "    predictor = MultiModalPredictor.load(\"e:\\Current_Workdir\\palm-fruit-classification\\autogluon_ver\\model\\master\\train_EfficientNetv2_8_2024-12-30_22-47-09\")\n",
      "    ```\n",
      "\n",
      "If you are not satisfied with the model, try to increase the training time, \n",
      "adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\n",
      "or post issues on GitHub (https://github.com/autogluon/autogluon/issues).\n",
      "\n",
      "\n",
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83/83 [00:07<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  9.44it/s]\n",
      "Model EfficientNetv2 (hyperparameters 8) train scores:\n",
      "  f1_macro: 0.999638471753412\n",
      "  f1_micro: 0.9992449981124952\n",
      "  accuracy: 0.9992449981124952\n",
      "  recall_macro: 0.999665327978581\n",
      "  precision_macro: 0.9996124031007753\n",
      "Model EfficientNetv2 (hyperparameters 8) test scores:\n",
      "  f1_macro: 0.8905912079329289\n",
      "  f1_micro: 0.8970976253298153\n",
      "  accuracy: 0.8970976253298153\n",
      "  recall_macro: 0.8813185338547659\n",
      "  precision_macro: 0.9036144262187821\n"
     ]
    }
   ],
   "source": [
    "create_and_train_model(hyperparam_8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.11.10\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          32\n",
      "Pytorch Version:    2.4.1\n",
      "CUDA Version:       12.4\n",
      "Memory Avail:       109.69 GB / 127.91 GB (85.8%)\n",
      "Disk Space Avail:   1393.41 GB / 1863.00 GB (74.8%)\n",
      "===================================================\n",
      "\n",
      "AutoMM starts to create your model. âœ¨âœ¨âœ¨\n",
      "\n",
      "To track the learning progress, you can open a terminal and launch Tensorboard:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir e:\\Current_Workdir\\palm-fruit-classification\\autogluon_ver\\model\\master\\train_EfficientNetv2_9_2024-12-30_22-58-35\n",
      "    ```\n",
      "\n",
      "Seed set to 0\n",
      "GPU Count: 1\n",
      "GPU Count to be Used: 1\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------\n",
      "0 | model             | TimmAutoModelForImagePrediction | 20.2 M | train\n",
      "1 | validation_metric | MulticlassF1Score               | 0      | train\n",
      "2 | loss_func         | FocalLoss                       | 0      | train\n",
      "------------------------------------------------------------------------------\n",
      "20.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "20.2 M    Total params\n",
      "80.741    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:15<00:15,  8.71it/s]                 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 8: 'val_f1_macro' reached 0.39475 (best 0.39475), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_9_2024-12-30_22-58-35\\\\epoch=0-step=8.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:33<00:00,  8.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 16: 'val_f1_macro' reached 0.64802 (best 0.64802), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_9_2024-12-30_22-58-35\\\\epoch=0-step=16.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:15<00:15,  8.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 25: 'val_f1_macro' reached 0.81614 (best 0.81614), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_9_2024-12-30_22-58-35\\\\epoch=1-step=25.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:34<00:00,  7.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 33: 'val_f1_macro' reached 0.84137 (best 0.84137), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_9_2024-12-30_22-58-35\\\\epoch=1-step=33.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:15<00:15,  8.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 42: 'val_f1_macro' reached 0.90333 (best 0.90333), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_9_2024-12-30_22-58-35\\\\epoch=2-step=42.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:33<00:00,  8.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 50: 'val_f1_macro' reached 0.91896 (best 0.91896), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_9_2024-12-30_22-58-35\\\\epoch=2-step=50.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:15<00:15,  8.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 59: 'val_f1_macro' reached 0.94680 (best 0.94680), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_9_2024-12-30_22-58-35\\\\epoch=3-step=59.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:32<00:00,  8.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 67: 'val_f1_macro' reached 0.95229 (best 0.95229), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_9_2024-12-30_22-58-35\\\\epoch=3-step=67.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:15<00:15,  8.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 76: 'val_f1_macro' reached 0.95293 (best 0.95293), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_9_2024-12-30_22-58-35\\\\epoch=4-step=76.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:32<00:00,  8.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 84: 'val_f1_macro' reached 0.96531 (best 0.96531), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_9_2024-12-30_22-58-35\\\\epoch=4-step=84.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:15<00:15,  8.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 93: 'val_f1_macro' reached 0.95920 (best 0.96531), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_9_2024-12-30_22-58-35\\\\epoch=5-step=93.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:32<00:00,  8.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 101: 'val_f1_macro' reached 0.96615 (best 0.96615), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\master\\\\train_EfficientNetv2_9_2024-12-30_22-58-35\\\\epoch=5-step=101.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 269/269 [00:35<00:00,  7.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=6` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 269/269 [00:35<00:00,  7.61it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\autogluon\\multimodal\\utils\\checkpoint.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  avg_state_dict = torch.load(checkpoint_paths[0], map_location=torch.device(\"cpu\"))[\"state_dict\"]\n",
      "AutoMM has created your model. ðŸŽ‰ðŸŽ‰ðŸŽ‰\n",
      "\n",
      "To load the model, use the code below:\n",
      "    ```python\n",
      "    from autogluon.multimodal import MultiModalPredictor\n",
      "    predictor = MultiModalPredictor.load(\"e:\\Current_Workdir\\palm-fruit-classification\\autogluon_ver\\model\\master\\train_EfficientNetv2_9_2024-12-30_22-58-35\")\n",
      "    ```\n",
      "\n",
      "If you are not satisfied with the model, try to increase the training time, \n",
      "adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\n",
      "or post issues on GitHub (https://github.com/autogluon/autogluon/issues).\n",
      "\n",
      "\n",
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83/83 [00:07<00:00, 11.51it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00, 10.63it/s]\n",
      "Model EfficientNetv2 (hyperparameters 9) train scores:\n",
      "  f1_macro: 0.9926517254607311\n",
      "  f1_micro: 0.9890524726311816\n",
      "  accuracy: 0.9890524726311816\n",
      "  recall_macro: 0.9949050280375581\n",
      "  precision_macro: 0.9904759836230589\n",
      "Model EfficientNetv2 (hyperparameters 9) test scores:\n",
      "  f1_macro: 0.8588517353276969\n",
      "  f1_micro: 0.8443271767810027\n",
      "  accuracy: 0.8443271767810027\n",
      "  recall_macro: 0.8739148264510583\n",
      "  precision_macro: 0.8550406939295828\n"
     ]
    }
   ],
   "source": [
    "create_and_train_model(hyperparam_9, 9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogluon_stable_112",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
