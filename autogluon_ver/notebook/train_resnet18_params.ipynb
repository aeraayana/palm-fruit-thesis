{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training ResNet-18 with Focal Loss on The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-12-26 16:40:04,620\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-12-26 16:40:04,747\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from autogluon.multimodal import MultiModalPredictor\n",
    "from ray import tune\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import torch\n",
    "import os\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"E:/Current_Workdir/palm-fruit-classification/data/clean/train_df.csv\")\n",
    "test_df = pd.read_csv(\"E:/Current_Workdir/palm-fruit-classification/data/clean/test_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning ResNet-18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate class proportions for Focal Loss $\\alpha$  \n",
    "see [this](https://amaarora.github.io/posts/2020-06-29-FocalLoss.html) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.1965174129353233,\n",
       " 1.1964769647696476,\n",
       " 0.44327309236947793,\n",
       " 5.660256410256411,\n",
       " 0.5145687645687645,\n",
       " 3.003401360544218]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(train_df[\"label_text\"]), y=train_df[\"label_text\"])\n",
    "class_weights_list = class_weights.tolist()\n",
    "class_weights_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Training Folder Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now = datetime.datetime.now()\n",
    "# timestamp_str = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "# model_path = \"../model/\" + f\"train_ResNet18_customParams_{timestamp_str}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs(model_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_model1 = {\n",
    "    \"optimization.learning_rate\": 0.000340352,\n",
    "    \"optimization.max_epochs\":17,\n",
    "    \"env.batch_size\": 8,\n",
    "    #\"env.batch_size\": tune.qlograndint(8,128,2),\n",
    "    \"optimization.loss_function\": \"focal_loss\",\n",
    "    \"optimization.focal_loss.alpha\": class_weights_list,\n",
    "    \"optimization.focal_loss.gamma\": 0.355163,\n",
    "    \"optimization.focal_loss.reduction\": \"sum\",\n",
    "    \"model.timm_image.checkpoint_name\": \"resnet18\",\n",
    "    \"optimization.optim_type\": \"adamw\",\n",
    "    \"optimization.top_k_average_method\": \"best\"\n",
    "}\n",
    "\n",
    "hyperparameters_model2 = {\n",
    "    \"optimization.learning_rate\": tune.loguniform(0.00005, 0.001),\n",
    "    \"optimization.max_epochs\":tune.randint(5,20),\n",
    "    \"env.batch_size\": tune.choice([8, 16, 32, 64, 128, 256]),\n",
    "    #\"env.batch_size\": tune.qlograndint(8,128,2),\n",
    "    \"optimization.loss_function\": \"focal_loss\",\n",
    "    \"optimization.focal_loss.alpha\": class_weights_list,\n",
    "    \"optimization.focal_loss.gamma\": tune.uniform(0, 1),\n",
    "    \"optimization.focal_loss.reduction\": \"sum\",\n",
    "    \"model.timm_image.checkpoint_name\": \"resnet18\",\n",
    "    \"optimization.optim_type\": \"adamw\",\n",
    "    \"optimization.top_k_average_method\": \"best\"\n",
    "}\n",
    "\n",
    "hyperparameters_model3 = {\n",
    "    \"optimization.learning_rate\": tune.loguniform(0.00005, 0.001),\n",
    "    \"optimization.max_epochs\":tune.randint(5,20),\n",
    "    \"env.batch_size\": tune.choice([8, 16, 32, 64, 128, 256]),\n",
    "    #\"env.batch_size\": tune.qlograndint(8,128,2),\n",
    "    \"optimization.loss_function\": \"focal_loss\",\n",
    "    \"optimization.focal_loss.alpha\": class_weights_list,\n",
    "    \"optimization.focal_loss.gamma\": tune.uniform(0, 1),\n",
    "    \"optimization.focal_loss.reduction\": \"sum\",\n",
    "    \"model.timm_image.checkpoint_name\": \"resnet18\",\n",
    "    \"optimization.optim_type\": \"adamw\",\n",
    "    \"optimization.top_k_average_method\": \"best\"\n",
    "}\n",
    "\n",
    "hyperparameters_model4 = {\n",
    "    \"optimization.learning_rate\": tune.loguniform(0.00005, 0.001),\n",
    "    \"optimization.max_epochs\":tune.randint(5,20),\n",
    "    \"env.batch_size\": tune.choice([8, 16, 32, 64, 128, 256]),\n",
    "    #\"env.batch_size\": tune.qlograndint(8,128,2),\n",
    "    \"optimization.loss_function\": \"focal_loss\",\n",
    "    \"optimization.focal_loss.alpha\": class_weights_list,\n",
    "    \"optimization.focal_loss.gamma\": tune.uniform(0, 1),\n",
    "    \"optimization.focal_loss.reduction\": \"sum\",\n",
    "    \"model.timm_image.checkpoint_name\": \"resnet18\",\n",
    "    \"optimization.optim_type\": \"adamw\",\n",
    "    \"optimization.top_k_average_method\": \"best\"\n",
    "}\n",
    "\n",
    "hyperparameters_model5 = {\n",
    "    \"optimization.learning_rate\": tune.loguniform(0.00005, 0.001),\n",
    "    \"optimization.max_epochs\":tune.randint(5,20),\n",
    "    \"env.batch_size\": tune.choice([8, 16, 32, 64, 128, 256]),\n",
    "    #\"env.batch_size\": tune.qlograndint(8,128,2),\n",
    "    \"optimization.loss_function\": \"focal_loss\",\n",
    "    \"optimization.focal_loss.alpha\": class_weights_list,\n",
    "    \"optimization.focal_loss.gamma\": tune.uniform(0, 1),\n",
    "    \"optimization.focal_loss.reduction\": \"sum\",\n",
    "    \"model.timm_image.checkpoint_name\": \"resnet18\",\n",
    "    \"optimization.optim_type\": \"adamw\",\n",
    "    \"optimization.top_k_average_method\": \"best\"\n",
    "}\n",
    "\n",
    "hyperparameters_model6 = {\n",
    "    \"optimization.learning_rate\": tune.loguniform(0.00005, 0.001),\n",
    "    \"optimization.max_epochs\":tune.randint(5,20),\n",
    "    \"env.batch_size\": tune.choice([8, 16, 32, 64, 128, 256]),\n",
    "    #\"env.batch_size\": tune.qlograndint(8,128,2),\n",
    "    \"optimization.loss_function\": \"focal_loss\",\n",
    "    \"optimization.focal_loss.alpha\": class_weights_list,\n",
    "    \"optimization.focal_loss.gamma\": tune.uniform(0, 1),\n",
    "    \"optimization.focal_loss.reduction\": \"sum\",\n",
    "    \"model.timm_image.checkpoint_name\": \"resnet18\",\n",
    "    \"optimization.optim_type\": \"adamw\",\n",
    "    \"optimization.top_k_average_method\": \"best\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_1 = MultiModalPredictor(label=\"label_text\", problem_type='multiclass', eval_metric=\"f1_macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter_tune_kwargs = {\n",
    "#     \"searcher\": \"bayes\",\n",
    "#     \"scheduler\": \"ASHA\",\n",
    "#     \"num_trials\": 1\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20241226_094305\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.11.10\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          32\n",
      "Pytorch Version:    2.4.1\n",
      "CUDA Version:       12.4\n",
      "Memory Avail:       109.09 GB / 127.91 GB (85.3%)\n",
      "Disk Space Avail:   1399.39 GB / 1863.00 GB (75.1%)\n",
      "===================================================\n",
      "\n",
      "AutoMM starts to create your model. âœ¨âœ¨âœ¨\n",
      "\n",
      "To track the learning progress, you can open a terminal and launch Tensorboard:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir e:\\Current_Workdir\\palm-fruit-classification\\autogluon_ver\\notebook\\AutogluonModels\\ag-20241226_094305\n",
      "    ```\n",
      "\n",
      "Seed set to 0\n",
      "GPU Count: 1\n",
      "GPU Count to be Used: 1\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------\n",
      "0 | model             | TimmAutoModelForImagePrediction | 11.2 M | train\n",
      "1 | validation_metric | MulticlassF1Score               | 0      | train\n",
      "2 | loss_func         | FocalLoss                       | 0      | train\n",
      "------------------------------------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.718    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 28.66it/s]                 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 134: 'val_f1_macro' reached 0.20254 (best 0.20254), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\notebook\\\\AutogluonModels\\\\ag-20241226_094305\\\\epoch=0-step=134.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:10<00:00, 25.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 268: 'val_f1_macro' reached 0.41876 (best 0.41876), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\notebook\\\\AutogluonModels\\\\ag-20241226_094305\\\\epoch=0-step=268.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 30.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 403: 'val_f1_macro' reached 0.55760 (best 0.55760), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\notebook\\\\AutogluonModels\\\\ag-20241226_094305\\\\epoch=1-step=403.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:10<00:00, 26.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 537: 'val_f1_macro' reached 0.73822 (best 0.73822), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\notebook\\\\AutogluonModels\\\\ag-20241226_094305\\\\epoch=1-step=537.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 29.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 672: 'val_f1_macro' reached 0.81098 (best 0.81098), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\notebook\\\\AutogluonModels\\\\ag-20241226_094305\\\\epoch=2-step=672.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:09<00:00, 27.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 806: 'val_f1_macro' reached 0.86770 (best 0.86770), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\notebook\\\\AutogluonModels\\\\ag-20241226_094305\\\\epoch=2-step=806.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 28.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 941: 'val_f1_macro' reached 0.86445 (best 0.86770), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\notebook\\\\AutogluonModels\\\\ag-20241226_094305\\\\epoch=3-step=941.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:10<00:00, 26.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 1075: 'val_f1_macro' reached 0.85883 (best 0.86770), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\notebook\\\\AutogluonModels\\\\ag-20241226_094305\\\\epoch=3-step=1075.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 29.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 1210: 'val_f1_macro' reached 0.89489 (best 0.89489), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\notebook\\\\AutogluonModels\\\\ag-20241226_094305\\\\epoch=4-step=1210.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:10<00:00, 26.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 1344: 'val_f1_macro' reached 0.92195 (best 0.92195), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\notebook\\\\AutogluonModels\\\\ag-20241226_094305\\\\epoch=4-step=1344.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 30.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 1479: 'val_f1_macro' reached 0.92668 (best 0.92668), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\notebook\\\\AutogluonModels\\\\ag-20241226_094305\\\\epoch=5-step=1479.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:09<00:00, 26.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 1613: 'val_f1_macro' reached 0.94223 (best 0.94223), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\notebook\\\\AutogluonModels\\\\ag-20241226_094305\\\\epoch=5-step=1613.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 29.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 1748: 'val_f1_macro' reached 0.95490 (best 0.95490), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\notebook\\\\AutogluonModels\\\\ag-20241226_094305\\\\epoch=6-step=1748.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:10<00:00, 26.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 1882: 'val_f1_macro' reached 0.96459 (best 0.96459), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\notebook\\\\AutogluonModels\\\\ag-20241226_094305\\\\epoch=6-step=1882.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 30.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 2017: 'val_f1_macro' reached 0.95873 (best 0.96459), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\notebook\\\\AutogluonModels\\\\ag-20241226_094305\\\\epoch=7-step=2017.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:10<00:00, 26.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 2151: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 29.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 2286: 'val_f1_macro' reached 0.97422 (best 0.97422), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\notebook\\\\AutogluonModels\\\\ag-20241226_094305\\\\epoch=8-step=2286.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:10<00:00, 26.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 2420: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 30.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 2555: 'val_f1_macro' reached 0.96231 (best 0.97422), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\notebook\\\\AutogluonModels\\\\ag-20241226_094305\\\\epoch=9-step=2555.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:09<00:00, 27.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 2689: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 30.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 2824: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:09<00:00, 28.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 2958: 'val_f1_macro' reached 0.97496 (best 0.97496), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\notebook\\\\AutogluonModels\\\\ag-20241226_094305\\\\epoch=10-step=2958.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 29.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 3093: 'val_f1_macro' reached 0.97749 (best 0.97749), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\notebook\\\\AutogluonModels\\\\ag-20241226_094305\\\\epoch=11-step=3093.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:10<00:00, 26.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 3227: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 30.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 3362: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:09<00:00, 29.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 3496: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 30.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 3631: 'val_f1_macro' reached 0.98040 (best 0.98040), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\notebook\\\\AutogluonModels\\\\ag-20241226_094305\\\\epoch=13-step=3631.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:10<00:00, 26.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 3765: 'val_f1_macro' reached 0.97848 (best 0.98040), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\notebook\\\\AutogluonModels\\\\ag-20241226_094305\\\\epoch=13-step=3765.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 29.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 3900: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:09<00:00, 28.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 4034: 'val_f1_macro' reached 0.97848 (best 0.98040), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\notebook\\\\AutogluonModels\\\\ag-20241226_094305\\\\epoch=14-step=4034.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 30.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 4169: 'val_f1_macro' reached 0.97873 (best 0.98040), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\notebook\\\\AutogluonModels\\\\ag-20241226_094305\\\\epoch=15-step=4169.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:09<00:00, 27.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 4303: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:04<00:04, 31.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 4438: 'val_f1_macro' reached 0.98452 (best 0.98452), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\notebook\\\\AutogluonModels\\\\ag-20241226_094305\\\\epoch=16-step=4438.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:09<00:00, 27.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 4572: 'val_f1_macro' reached 0.98189 (best 0.98452), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\notebook\\\\AutogluonModels\\\\ag-20241226_094305\\\\epoch=16-step=4572.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 269/269 [00:11<00:00, 24.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=17` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 269/269 [00:11<00:00, 24.43it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\autogluon\\multimodal\\utils\\checkpoint.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  avg_state_dict = torch.load(checkpoint_paths[0], map_location=torch.device(\"cpu\"))[\"state_dict\"]\n",
      "AutoMM has created your model. ðŸŽ‰ðŸŽ‰ðŸŽ‰\n",
      "\n",
      "To load the model, use the code below:\n",
      "    ```python\n",
      "    from autogluon.multimodal import MultiModalPredictor\n",
      "    predictor = MultiModalPredictor.load(\"e:\\Current_Workdir\\palm-fruit-classification\\autogluon_ver\\notebook\\AutogluonModels\\ag-20241226_094305\")\n",
      "    ```\n",
      "\n",
      "If you are not satisfied with the model, try to increase the training time, \n",
      "adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\n",
      "or post issues on GitHub (https://github.com/autogluon/autogluon/issues).\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.multimodal.predictor.MultiModalPredictor at 0x2181e9d06d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_1.fit(\n",
    "        train_data=train_df,\n",
    "        hyperparameters=hyperparameters_model1,\n",
    "        # time_limit = 3600\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictor1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor1\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate(train_df, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1_macro\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1_micro\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecall_macro\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision_macro\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      2\u001b[0m scores\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictor1' is not defined"
     ]
    }
   ],
   "source": [
    "scores = predictor1.evaluate(train_df, metrics=[\"f1_macro\", \"f1_micro\", \"accuracy\", \"recall_macro\", \"precision_macro\"])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predictor.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = test_df['label_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(true_labels, preds)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=predictor.class_labels)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = test_df.iloc[0]['image']\n",
    "pil_img = Image.open(image_path)  # Use .open() instead of calling Image\n",
    "display(pil_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictor.predict({'image': [image_path]})\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = predictor.predict_proba({'image': [image_path]})\n",
    "print(proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = predictor.extract_embedding({'image': [image_path]})\n",
    "print(feature[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Raw TIMM Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.dump_model(model_path + \"/timm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogluon_stable_112",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
