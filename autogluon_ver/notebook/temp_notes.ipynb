{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temp Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Inference on Raw TIMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Configuration from your JSON\n",
    "config = {\n",
    "    \"architecture\": \"maxvit_rmlp_pico_rw_256\",\n",
    "    \"num_classes\": 4,\n",
    "    \"num_features\": 256,\n",
    "    \"global_pool\": \"avg\",\n",
    "    \"pretrained_cfg\": {\n",
    "        \"tag\": \"sw_in1k\",\n",
    "        \"custom_load\": False,\n",
    "        \"input_size\": [3, 256, 256],\n",
    "        \"fixed_input_size\": True,\n",
    "        \"interpolation\": \"bicubic\",\n",
    "        \"crop_pct\": 0.95,\n",
    "        \"crop_mode\": \"center\",\n",
    "        \"mean\": [0.5, 0.5, 0.5],\n",
    "        \"std\": [0.5, 0.5, 0.5],\n",
    "        \"num_classes\": 1000,\n",
    "        \"pool_size\": [8, 8],\n",
    "        \"first_conv\": \"stem.conv1\",\n",
    "        \"classifier\": \"head.fc\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Path to your checkpoint file\n",
    "checkpoint_path = \"checkpoint.bin\"\n",
    "\n",
    "# Instantiate the model\n",
    "model = timm.create_model(\n",
    "    config[\"architecture\"],  # Model architecture\n",
    "    pretrained=False,        # Skip loading pretrained weights from timm\n",
    "    num_classes=config[\"num_classes\"],  # Adjust final layer for 4 classes\n",
    "    global_pool=config[\"global_pool\"]   # Set global pooling\n",
    ")\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"))  # Adjust map_location as needed\n",
    "if \"state_dict\" in checkpoint:\n",
    "    state_dict = checkpoint[\"state_dict\"]  # For structured checkpoint files\n",
    "else:\n",
    "    state_dict = checkpoint\n",
    "\n",
    "# Strip prefixes if necessary (e.g., 'module.')\n",
    "state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "\n",
    "# Load weights into the model\n",
    "model.load_state_dict(state_dict, strict=False)  # Use strict=True for strict matching\n",
    "\n",
    "# Example preprocessing pipeline\n",
    "input_size = config[\"pretrained_cfg\"][\"input_size\"][1:]  # (256, 256)\n",
    "mean = config[\"pretrained_cfg\"][\"mean\"]\n",
    "std = config[\"pretrained_cfg\"][\"std\"]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(input_size, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop(int(input_size[0] * config[\"pretrained_cfg\"][\"crop_pct\"])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std),\n",
    "])\n",
    "\n",
    "# Example image (replace with your own image file path)\n",
    "image_path = \"example.jpg\"\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "image_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Inference\n",
    "model.eval()  # Set model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    outputs = model(image_tensor)  # Forward pass\n",
    "    predictions = torch.softmax(outputs, dim=1)  # Convert logits to probabilities\n",
    "\n",
    "print(\"Predictions:\", predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Additions\n",
    "Loading the Checkpoint:\n",
    "\n",
    "torch.load(checkpoint_path) reads the checkpoint file.\n",
    "The checkpoint might include either a state_dict or the weights directly. Adjust based on your checkpoint structure.\n",
    "Prefix Handling:\n",
    "\n",
    "Check if the state_dict keys have a prefix like module. (common when training with DataParallel) and strip it if necessary.\n",
    "Loading into the Model:\n",
    "\n",
    "model.load_state_dict(state_dict, strict=False) loads the weights. If the strict flag is True, it will enforce an exact match between the model's layers and the checkpoint.\n",
    "Skipping Pretrained Weights:\n",
    "\n",
    "pretrained=False ensures no weights from timm are loaded since your checkpoint provides the weights.\n",
    "Things to Check\n",
    "Checkpoint Compatibility:\n",
    "\n",
    "Ensure your checkpoint was trained on the same architecture as defined in the config.\n",
    "Verify the num_classes matches the checkpoint training.\n",
    "Adjusting Device:\n",
    "\n",
    "For GPU inference, move the model and data to the GPU:\n",
    "python\n",
    "Copy code\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "image_tensor = image_tensor.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trackable Hyperparameter Tuning by Exposing Ray Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.bayesopt import BayesOptSearch\n",
    "from autogluon.multimodal import MultiModalPredictor\n",
    "\n",
    "# ASHA Scheduler\n",
    "asha_scheduler = ASHAScheduler(\n",
    "    metric=\"f1_macro\",  # Metric to optimize\n",
    "    mode=\"max\",         # Maximize F1-macro\n",
    "    grace_period=1,     # Minimum number of epochs before stopping trials\n",
    "    max_t=20            # Maximum number of epochs\n",
    ")\n",
    "\n",
    "# Bayesian Optimization Search\n",
    "bayesopt_search = BayesOptSearch(\n",
    "    metric=\"f1_macro\",  # Metric to optimize\n",
    "    mode=\"max\",         # Maximize F1-macro\n",
    ")\n",
    "\n",
    "# Define the search space\n",
    "search_space = {\n",
    "    \"optimization.learning_rate\": tune.loguniform(0.00001, 0.001),\n",
    "    \"optimization.max_epochs\": tune.randint(5, 20),\n",
    "    \"env.batch_size\": tune.choice([8, 16, 32, 64, 128, 256]),\n",
    "    \"optimization.loss_function\": \"focal_loss\",\n",
    "    \"optimization.focal_loss.alpha\": [class_weights_list],  # Predefined class weights\n",
    "    \"optimization.focal_loss.gamma\": tune.uniform(1, 3),\n",
    "    \"optimization.focal_loss.reduction\": \"sum\",\n",
    "    \"model.timm_image.checkpoint_name\": \"efficientnet_b2\",\n",
    "    \"optimization.optim_type\": \"adamw\",\n",
    "    \"optimization.top_k_average_method\": \"best\",\n",
    "}\n",
    "\n",
    "# Train function remains the same\n",
    "def train_multimodal(config):\n",
    "    predictor = MultiModalPredictor(\n",
    "        label=\"label_column\",\n",
    "        problem_type=\"classification\",\n",
    "        eval_metric=\"f1_macro\"\n",
    "    )\n",
    "    predictor.fit(\n",
    "        train_data=\"path_to_train.csv\",\n",
    "        hyperparameters=config,\n",
    "        time_limit=600\n",
    "    )\n",
    "    evaluation_metrics = predictor.evaluate(\"path_to_val.csv\")\n",
    "    f1_macro_score = evaluation_metrics[\"f1_macro\"]\n",
    "    tune.report(f1_macro=f1_macro_score)\n",
    "\n",
    "# Run hyperparameter tuning with Ray\n",
    "analysis = tune.run(\n",
    "    train_multimodal,\n",
    "    config=search_space,\n",
    "    metric=\"f1_macro\",  # Metric to optimize\n",
    "    mode=\"max\",         # Maximize F1-macro\n",
    "    num_samples=10,     # Number of trials\n",
    "    search_alg=bayesopt_search,\n",
    "    scheduler=asha_scheduler,\n",
    "    resources_per_trial={\"cpu\": 4, \"gpu\": 1},  # Adjust based on your hardware\n",
    ")\n",
    "\n",
    "# Access results\n",
    "print(\"Best hyperparameters found:\", analysis.best_config)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogluon_112",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
