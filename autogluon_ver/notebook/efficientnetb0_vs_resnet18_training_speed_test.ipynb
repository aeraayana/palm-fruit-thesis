{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNet-B0 vs ResNet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-12-05 16:48:47,831\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-12-05 16:48:47,940\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from autogluon.multimodal import MultiModalPredictor\n",
    "from ray import tune\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"E:/Current_Workdir/palm-fruit-classification/data/clean/train_df.csv\")\n",
    "test_df = pd.read_csv(\"E:/Current_Workdir/palm-fruit-classification/data/clean/test_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.1965174129353233,\n",
       " 1.1964769647696476,\n",
       " 0.44327309236947793,\n",
       " 5.660256410256411,\n",
       " 0.5145687645687645,\n",
       " 3.003401360544218]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(train_df[\"label_text\"]), y=train_df[\"label_text\"])\n",
    "class_weights_list = class_weights.tolist()\n",
    "class_weights_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNet-B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "timestamp_str = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "model_path_efficientnet = \"../model/\" + f\"train_EfficientNetB0_dummy_{timestamp_str}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../model/train_EfficientNetB0_dummy_2024-12-05_16-48-48'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path_efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(model_path_efficientnet, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_efficientnet = {\n",
    "    \"optimization.learning_rate\": 0.0005,\n",
    "    \"optimization.max_epochs\":10,\n",
    "    \"env.batch_size\": 32,\n",
    "    \"model.timm_image.checkpoint_name\": \"efficientnet_b0\",\n",
    "    \"optimization.focal_loss.alpha\": class_weights_list,\n",
    "    \"optimization.focal_loss.gamma\": 2,\n",
    "    \"optimization.optim_type\": \"adamw\",\n",
    "    \"optimization.top_k_average_method\": \"best\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_efficientnet = MultiModalPredictor(label=\"label_text\", path=model_path_efficientnet, problem_type='multiclass', eval_metric=\"f1_macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.11.10\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          32\n",
      "Pytorch Version:    2.4.1\n",
      "CUDA Version:       12.4\n",
      "Memory Avail:       107.74 GB / 127.91 GB (84.2%)\n",
      "Disk Space Avail:   1455.32 GB / 1863.00 GB (78.1%)\n",
      "===================================================\n",
      "\n",
      "AutoMM starts to create your model. âœ¨âœ¨âœ¨\n",
      "\n",
      "To track the learning progress, you can open a terminal and launch Tensorboard:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir e:\\Current_Workdir\\palm-fruit-classification\\autogluon_ver\\model\\train_EfficientNetB0_dummy_2024-12-05_16-48-48\n",
      "    ```\n",
      "\n",
      "Seed set to 0\n",
      "GPU Count: 1\n",
      "GPU Count to be Used: 1\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------\n",
      "0 | model             | TimmAutoModelForImagePrediction | 4.0 M  | train\n",
      "1 | validation_metric | MulticlassF1Score               | 0      | train\n",
      "2 | loss_func         | CrossEntropyLoss                | 0      | train\n",
      "------------------------------------------------------------------------------\n",
      "4.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.0 M     Total params\n",
      "16.061    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:10<00:10, 13.10it/s]                 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 33: 'val_f1_macro' reached 0.48663 (best 0.48663), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_EfficientNetB0_dummy_2024-12-05_16-48-48\\\\epoch=0-step=33.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:21<00:00, 12.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 67: 'val_f1_macro' reached 0.75962 (best 0.75962), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_EfficientNetB0_dummy_2024-12-05_16-48-48\\\\epoch=0-step=67.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:09<00:09, 13.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 101: 'val_f1_macro' reached 0.85795 (best 0.85795), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_EfficientNetB0_dummy_2024-12-05_16-48-48\\\\epoch=1-step=101.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:20<00:00, 13.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 135: 'val_f1_macro' reached 0.89149 (best 0.89149), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_EfficientNetB0_dummy_2024-12-05_16-48-48\\\\epoch=1-step=135.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:10<00:10, 13.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 169: 'val_f1_macro' reached 0.90427 (best 0.90427), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_EfficientNetB0_dummy_2024-12-05_16-48-48\\\\epoch=2-step=169.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:20<00:00, 12.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 203: 'val_f1_macro' reached 0.93242 (best 0.93242), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_EfficientNetB0_dummy_2024-12-05_16-48-48\\\\epoch=2-step=203.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:09<00:09, 13.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 237: 'val_f1_macro' reached 0.91655 (best 0.93242), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_EfficientNetB0_dummy_2024-12-05_16-48-48\\\\epoch=3-step=237.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:20<00:00, 13.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 271: 'val_f1_macro' reached 0.94396 (best 0.94396), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_EfficientNetB0_dummy_2024-12-05_16-48-48\\\\epoch=3-step=271.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:09<00:09, 13.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 305: 'val_f1_macro' reached 0.97906 (best 0.97906), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_EfficientNetB0_dummy_2024-12-05_16-48-48\\\\epoch=4-step=305.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:20<00:00, 13.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 339: 'val_f1_macro' reached 0.96202 (best 0.97906), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_EfficientNetB0_dummy_2024-12-05_16-48-48\\\\epoch=4-step=339.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:09<00:10, 13.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 373: 'val_f1_macro' reached 0.98098 (best 0.98098), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_EfficientNetB0_dummy_2024-12-05_16-48-48\\\\epoch=5-step=373.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:20<00:00, 13.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 407: 'val_f1_macro' reached 0.98332 (best 0.98332), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_EfficientNetB0_dummy_2024-12-05_16-48-48\\\\epoch=5-step=407.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:10<00:10, 12.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 441: 'val_f1_macro' reached 0.98520 (best 0.98520), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_EfficientNetB0_dummy_2024-12-05_16-48-48\\\\epoch=6-step=441.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:20<00:00, 12.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 475: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:10<00:10, 13.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 509: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:20<00:00, 13.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 543: 'val_f1_macro' reached 0.98332 (best 0.98520), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_EfficientNetB0_dummy_2024-12-05_16-48-48\\\\epoch=7-step=543.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:09<00:10, 13.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 577: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:20<00:00, 13.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 611: 'val_f1_macro' reached 0.98627 (best 0.98627), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_EfficientNetB0_dummy_2024-12-05_16-48-48\\\\epoch=8-step=611.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:09<00:09, 14.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 645: 'val_f1_macro' reached 0.98464 (best 0.98627), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_EfficientNetB0_dummy_2024-12-05_16-48-48\\\\epoch=9-step=645.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:20<00:00, 13.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 679: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 269/269 [00:20<00:00, 13.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 269/269 [00:20<00:00, 13.11it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\autogluon\\multimodal\\utils\\checkpoint.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  avg_state_dict = torch.load(checkpoint_paths[0], map_location=torch.device(\"cpu\"))[\"state_dict\"]\n",
      "AutoMM has created your model. ðŸŽ‰ðŸŽ‰ðŸŽ‰\n",
      "\n",
      "To load the model, use the code below:\n",
      "    ```python\n",
      "    from autogluon.multimodal import MultiModalPredictor\n",
      "    predictor = MultiModalPredictor.load(\"e:\\Current_Workdir\\palm-fruit-classification\\autogluon_ver\\model\\train_EfficientNetB0_dummy_2024-12-05_16-48-48\")\n",
      "    ```\n",
      "\n",
      "If you are not satisfied with the model, try to increase the training time, \n",
      "adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\n",
      "or post issues on GitHub (https://github.com/autogluon/autogluon/issues).\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 243.82 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "predictor_efficientnet.fit(\n",
    "    train_data=train_df,\n",
    "    hyperparameters=hyperparameters_efficientnet,\n",
    "    hyperparameter_tune_kwargs=None\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and display training time\n",
    "training_time = end_time - start_time\n",
    "print(f\"Training completed in {training_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:00<00:00, 22.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1_macro': 0.9044358525012437,\n",
       " 'f1_micro': 0.8812664907651715,\n",
       " 'accuracy': 0.8812664907651715,\n",
       " 'recall_macro': 0.916936927806493,\n",
       " 'precision_macro': 0.8976004012331993}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_efficientnet = predictor_efficientnet.evaluate(test_df, metrics=[\"f1_macro\", \"f1_micro\", \"accuracy\", \"recall_macro\", \"precision_macro\"])\n",
    "scores_efficientnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "timestamp_str = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "model_path_resnet = \"../model/\" + f\"train_ResNet18_dummy_{timestamp_str}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../model/train_ResNet18_dummy_2024-12-05_16-53-00'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(model_path_resnet, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_resnet = {\n",
    "    \"optimization.learning_rate\": 0.0005,\n",
    "    \"optimization.max_epochs\":10,\n",
    "    \"env.batch_size\": 32,\n",
    "    \"optimization.focal_loss.alpha\": class_weights_list,\n",
    "    \"optimization.focal_loss.gamma\": 2,\n",
    "    \"model.timm_image.checkpoint_name\": \"resnet18\",\n",
    "    \"optimization.optim_type\": \"adamw\",\n",
    "    \"optimization.top_k_average_method\": \"best\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_resnet = MultiModalPredictor(label=\"label_text\", path=model_path_resnet, problem_type='multiclass', eval_metric=\"f1_macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.11.10\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          32\n",
      "Pytorch Version:    2.4.1\n",
      "CUDA Version:       12.4\n",
      "Memory Avail:       106.49 GB / 127.91 GB (83.3%)\n",
      "Disk Space Avail:   1455.30 GB / 1863.00 GB (78.1%)\n",
      "===================================================\n",
      "\n",
      "AutoMM starts to create your model. âœ¨âœ¨âœ¨\n",
      "\n",
      "To track the learning progress, you can open a terminal and launch Tensorboard:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir e:\\Current_Workdir\\palm-fruit-classification\\autogluon_ver\\model\\train_ResNet18_dummy_2024-12-05_16-53-00\n",
      "    ```\n",
      "\n",
      "Seed set to 0\n",
      "GPU Count: 1\n",
      "GPU Count to be Used: 1\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------\n",
      "0 | model             | TimmAutoModelForImagePrediction | 11.2 M | train\n",
      "1 | validation_metric | MulticlassF1Score               | 0      | train\n",
      "2 | loss_func         | CrossEntropyLoss                | 0      | train\n",
      "------------------------------------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.718    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:03<00:03, 35.49it/s]                 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 33: 'val_f1_macro' reached 0.17321 (best 0.17321), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_ResNet18_dummy_2024-12-05_16-53-00\\\\epoch=0-step=33.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:08<00:00, 31.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 67: 'val_f1_macro' reached 0.21185 (best 0.21185), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_ResNet18_dummy_2024-12-05_16-53-00\\\\epoch=0-step=67.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:03<00:03, 37.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 101: 'val_f1_macro' reached 0.42189 (best 0.42189), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_ResNet18_dummy_2024-12-05_16-53-00\\\\epoch=1-step=101.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:08<00:00, 32.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 135: 'val_f1_macro' reached 0.52219 (best 0.52219), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_ResNet18_dummy_2024-12-05_16-53-00\\\\epoch=1-step=135.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:03<00:03, 37.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 169: 'val_f1_macro' reached 0.60919 (best 0.60919), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_ResNet18_dummy_2024-12-05_16-53-00\\\\epoch=2-step=169.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:08<00:00, 33.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 203: 'val_f1_macro' reached 0.67971 (best 0.67971), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_ResNet18_dummy_2024-12-05_16-53-00\\\\epoch=2-step=203.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:03<00:03, 38.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 237: 'val_f1_macro' reached 0.70788 (best 0.70788), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_ResNet18_dummy_2024-12-05_16-53-00\\\\epoch=3-step=237.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:08<00:00, 32.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 271: 'val_f1_macro' reached 0.73331 (best 0.73331), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_ResNet18_dummy_2024-12-05_16-53-00\\\\epoch=3-step=271.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:03<00:03, 38.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 305: 'val_f1_macro' reached 0.74268 (best 0.74268), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_ResNet18_dummy_2024-12-05_16-53-00\\\\epoch=4-step=305.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:08<00:00, 32.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 339: 'val_f1_macro' reached 0.85522 (best 0.85522), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_ResNet18_dummy_2024-12-05_16-53-00\\\\epoch=4-step=339.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:03<00:03, 38.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 373: 'val_f1_macro' reached 0.85680 (best 0.85680), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_ResNet18_dummy_2024-12-05_16-53-00\\\\epoch=5-step=373.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:08<00:00, 32.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 407: 'val_f1_macro' reached 0.88944 (best 0.88944), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_ResNet18_dummy_2024-12-05_16-53-00\\\\epoch=5-step=407.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:03<00:03, 38.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 441: 'val_f1_macro' reached 0.89837 (best 0.89837), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_ResNet18_dummy_2024-12-05_16-53-00\\\\epoch=6-step=441.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:08<00:00, 32.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 475: 'val_f1_macro' reached 0.89916 (best 0.89916), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_ResNet18_dummy_2024-12-05_16-53-00\\\\epoch=6-step=475.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:03<00:03, 36.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 509: 'val_f1_macro' reached 0.91799 (best 0.91799), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_ResNet18_dummy_2024-12-05_16-53-00\\\\epoch=7-step=509.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:08<00:00, 31.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 543: 'val_f1_macro' reached 0.91636 (best 0.91799), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_ResNet18_dummy_2024-12-05_16-53-00\\\\epoch=7-step=543.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:03<00:03, 39.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 577: 'val_f1_macro' reached 0.91942 (best 0.91942), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_ResNet18_dummy_2024-12-05_16-53-00\\\\epoch=8-step=577.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:07<00:00, 33.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 611: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:03<00:03, 40.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 645: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:07<00:00, 37.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 679: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 269/269 [00:07<00:00, 34.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 269/269 [00:07<00:00, 34.68it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\autogluon\\multimodal\\utils\\checkpoint.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  avg_state_dict = torch.load(checkpoint_paths[0], map_location=torch.device(\"cpu\"))[\"state_dict\"]\n",
      "AutoMM has created your model. ðŸŽ‰ðŸŽ‰ðŸŽ‰\n",
      "\n",
      "To load the model, use the code below:\n",
      "    ```python\n",
      "    from autogluon.multimodal import MultiModalPredictor\n",
      "    predictor = MultiModalPredictor.load(\"e:\\Current_Workdir\\palm-fruit-classification\\autogluon_ver\\model\\train_ResNet18_dummy_2024-12-05_16-53-00\")\n",
      "    ```\n",
      "\n",
      "If you are not satisfied with the model, try to increase the training time, \n",
      "adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\n",
      "or post issues on GitHub (https://github.com/autogluon/autogluon/issues).\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 121.79 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "predictor_resnet.fit(\n",
    "    train_data=train_df,\n",
    "    hyperparameters=hyperparameters_resnet,\n",
    "    hyperparameter_tune_kwargs=None\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and display training time\n",
    "training_time = end_time - start_time\n",
    "print(f\"Training completed in {training_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load pretrained checkpoint: e:\\Current_Workdir\\palm-fruit-classification\\autogluon_ver\\model\\train_ResNet18_dummy_2024-12-05_14-47-44\\model.ckpt\n",
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\autogluon\\multimodal\\learners\\base.py:2111: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=torch.device(\"cpu\"))[\"state_dict\"]\n"
     ]
    }
   ],
   "source": [
    "predictor_resnet = MultiModalPredictor.load(\"e:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_ResNet18_dummy_2024-12-05_14-47-44\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:00<00:00, 21.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1_macro': 0.8151877690628434,\n",
       " 'f1_micro': 0.8654353562005277,\n",
       " 'accuracy': 0.8654353562005277,\n",
       " 'recall_macro': 0.7840869878913357,\n",
       " 'precision_macro': 0.8561700376917768}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_resnet = predictor_resnet.evaluate(test_df, metrics=[\"f1_macro\", \"f1_micro\", \"accuracy\", \"recall_macro\", \"precision_macro\"])\n",
    "scores_resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNet B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "timestamp_str = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "model_path_efficientnet_b2 = \"../model/\" + f\"train_EfficientNetB2_dummy_{timestamp_str}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../model/train_EfficientNetB2_dummy_2024-12-05_16-55-12'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path_efficientnet_b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(model_path_efficientnet_b2, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.11.10\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          32\n",
      "Pytorch Version:    2.4.1\n",
      "CUDA Version:       12.4\n",
      "Memory Avail:       106.25 GB / 127.91 GB (83.1%)\n",
      "Disk Space Avail:   1455.27 GB / 1863.00 GB (78.1%)\n",
      "===================================================\n",
      "\n",
      "AutoMM starts to create your model. âœ¨âœ¨âœ¨\n",
      "\n",
      "To track the learning progress, you can open a terminal and launch Tensorboard:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir e:\\Current_Workdir\\palm-fruit-classification\\autogluon_ver\\model\\train_EfficientNetB2_dummy_2024-12-05_16-55-12\n",
      "    ```\n",
      "\n",
      "Seed set to 0\n",
      "GPU Count: 1\n",
      "GPU Count to be Used: 1\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------\n",
      "0 | model             | TimmAutoModelForImagePrediction | 7.7 M  | train\n",
      "1 | validation_metric | MulticlassF1Score               | 0      | train\n",
      "2 | loss_func         | CrossEntropyLoss                | 0      | train\n",
      "------------------------------------------------------------------------------\n",
      "7.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.7 M     Total params\n",
      "30.838    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:13<00:13, 10.08it/s]                 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 33: 'val_f1_macro' reached 0.54806 (best 0.54806), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_EfficientNetB2_dummy_2024-12-05_16-55-12\\\\epoch=0-step=33.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:27<00:00,  9.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 67: 'val_f1_macro' reached 0.78213 (best 0.78213), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_EfficientNetB2_dummy_2024-12-05_16-55-12\\\\epoch=0-step=67.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:12<00:12, 10.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 101: 'val_f1_macro' reached 0.84297 (best 0.84297), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_EfficientNetB2_dummy_2024-12-05_16-55-12\\\\epoch=1-step=101.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:25<00:00, 10.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 135: 'val_f1_macro' reached 0.85859 (best 0.85859), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_EfficientNetB2_dummy_2024-12-05_16-55-12\\\\epoch=1-step=135.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:12<00:13, 10.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 169: 'val_f1_macro' reached 0.92792 (best 0.92792), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_EfficientNetB2_dummy_2024-12-05_16-55-12\\\\epoch=2-step=169.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:27<00:00,  9.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 203: 'val_f1_macro' reached 0.94259 (best 0.94259), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_EfficientNetB2_dummy_2024-12-05_16-55-12\\\\epoch=2-step=203.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:12<00:12, 10.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 237: 'val_f1_macro' reached 0.96995 (best 0.96995), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_EfficientNetB2_dummy_2024-12-05_16-55-12\\\\epoch=3-step=237.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:26<00:00, 10.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 271: 'val_f1_macro' reached 0.97130 (best 0.97130), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_EfficientNetB2_dummy_2024-12-05_16-55-12\\\\epoch=3-step=271.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:12<00:12, 10.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 305: 'val_f1_macro' reached 0.98516 (best 0.98516), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_EfficientNetB2_dummy_2024-12-05_16-55-12\\\\epoch=4-step=305.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:26<00:00, 10.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 339: 'val_f1_macro' reached 0.97943 (best 0.98516), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_EfficientNetB2_dummy_2024-12-05_16-55-12\\\\epoch=4-step=339.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:13<00:13, 10.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 373: 'val_f1_macro' reached 0.97646 (best 0.98516), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_EfficientNetB2_dummy_2024-12-05_16-55-12\\\\epoch=5-step=373.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:26<00:00,  9.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 407: 'val_f1_macro' reached 0.98788 (best 0.98788), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_EfficientNetB2_dummy_2024-12-05_16-55-12\\\\epoch=5-step=407.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:12<00:12, 10.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 441: 'val_f1_macro' reached 0.98767 (best 0.98788), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_EfficientNetB2_dummy_2024-12-05_16-55-12\\\\epoch=6-step=441.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:27<00:00,  9.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 475: 'val_f1_macro' reached 0.99288 (best 0.99288), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_EfficientNetB2_dummy_2024-12-05_16-55-12\\\\epoch=6-step=475.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:13<00:13, 10.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 509: 'val_f1_macro' reached 0.99577 (best 0.99577), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_EfficientNetB2_dummy_2024-12-05_16-55-12\\\\epoch=7-step=509.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:26<00:00, 10.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 543: 'val_f1_macro' reached 0.99809 (best 0.99809), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_EfficientNetB2_dummy_2024-12-05_16-55-12\\\\epoch=7-step=543.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:12<00:12, 10.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 577: 'val_f1_macro' reached 0.99385 (best 0.99809), saving model to 'E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\autogluon_ver\\\\model\\\\train_EfficientNetB2_dummy_2024-12-05_16-55-12\\\\epoch=8-step=577.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:26<00:00,  9.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 611: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 134/269 [00:12<00:12, 10.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 645: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 268/269 [00:25<00:00, 10.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 679: 'val_f1_macro' was not in top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 269/269 [00:26<00:00, 10.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 269/269 [00:26<00:00, 10.14it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\autogluon\\multimodal\\utils\\checkpoint.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  avg_state_dict = torch.load(checkpoint_paths[0], map_location=torch.device(\"cpu\"))[\"state_dict\"]\n",
      "AutoMM has created your model. ðŸŽ‰ðŸŽ‰ðŸŽ‰\n",
      "\n",
      "To load the model, use the code below:\n",
      "    ```python\n",
      "    from autogluon.multimodal import MultiModalPredictor\n",
      "    predictor = MultiModalPredictor.load(\"e:\\Current_Workdir\\palm-fruit-classification\\autogluon_ver\\model\\train_EfficientNetB2_dummy_2024-12-05_16-55-12\")\n",
      "    ```\n",
      "\n",
      "If you are not satisfied with the model, try to increase the training time, \n",
      "adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\n",
      "or post issues on GitHub (https://github.com/autogluon/autogluon/issues).\n",
      "\n",
      "\n",
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 308.04 seconds.\n",
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:00<00:00, 17.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1_macro': 0.9030315972115638,\n",
       " 'f1_micro': 0.8918205804749341,\n",
       " 'accuracy': 0.8918205804749341,\n",
       " 'recall_macro': 0.8989051139413459,\n",
       " 'precision_macro': 0.9079285404758465}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters_efficientnet_b2 = {\n",
    "    \"optimization.learning_rate\": 0.0005,\n",
    "    \"optimization.max_epochs\":10,\n",
    "    \"env.batch_size\": 32,\n",
    "    \"optimization.focal_loss.alpha\": class_weights_list,\n",
    "    \"optimization.focal_loss.gamma\": 2,\n",
    "    \"model.timm_image.checkpoint_name\": \"efficientnet_b2\",\n",
    "    \"optimization.optim_type\": \"adamw\",\n",
    "    \"optimization.top_k_average_method\": \"best\"\n",
    "}\n",
    "\n",
    "predictor_efficientnet_b2 = MultiModalPredictor(label=\"label_text\", path=model_path_efficientnet_b2, problem_type='multiclass', eval_metric=\"f1_macro\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "predictor_efficientnet_b2.fit(\n",
    "    train_data=train_df,\n",
    "    hyperparameters=hyperparameters_efficientnet_b2,\n",
    "    hyperparameter_tune_kwargs=None\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and display training time\n",
    "training_time = end_time - start_time\n",
    "print(f\"Training completed in {training_time:.2f} seconds.\")\n",
    "\n",
    "scores_efficientnet_b2 = predictor_efficientnet_b2.evaluate(test_df, metrics=[\"f1_macro\", \"f1_micro\", \"accuracy\", \"recall_macro\", \"precision_macro\"])\n",
    "scores_efficientnet_b2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogluon_stable_112",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
