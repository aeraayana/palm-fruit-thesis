{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying out Autogluon for Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from autogluon.multimodal.utils.misc import shopee_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 14:24:57,174\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-12-04 14:24:57,273\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from autogluon.multimodal import MultiModalPredictor\n",
    "from autogluon.multimodal.presets import get_automm_presets\n",
    "from IPython.display import Image, display\n",
    "from ray import tune\n",
    "from datetime import datetime\n",
    "from contextlib import redirect_stdout\n",
    "import json\n",
    "import yaml\n",
    "import uuid\n",
    "import logging\n",
    "import sys\n",
    "from io import StringIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dir = './ag_automm_tutorial_imgcls'\n",
    "train_data_path, test_data_path = shopee_dataset(download_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e:\\Current_Workdir\\palm-fruit-classification\\o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e:\\Current_Workdir\\palm-fruit-classification\\o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e:\\Current_Workdir\\palm-fruit-classification\\o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e:\\Current_Workdir\\palm-fruit-classification\\o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e:\\Current_Workdir\\palm-fruit-classification\\o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>e:\\Current_Workdir\\palm-fruit-classification\\o...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>e:\\Current_Workdir\\palm-fruit-classification\\o...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>e:\\Current_Workdir\\palm-fruit-classification\\o...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>e:\\Current_Workdir\\palm-fruit-classification\\o...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>e:\\Current_Workdir\\palm-fruit-classification\\o...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 image  label\n",
       "0    e:\\Current_Workdir\\palm-fruit-classification\\o...      0\n",
       "1    e:\\Current_Workdir\\palm-fruit-classification\\o...      0\n",
       "2    e:\\Current_Workdir\\palm-fruit-classification\\o...      0\n",
       "3    e:\\Current_Workdir\\palm-fruit-classification\\o...      0\n",
       "4    e:\\Current_Workdir\\palm-fruit-classification\\o...      0\n",
       "..                                                 ...    ...\n",
       "795  e:\\Current_Workdir\\palm-fruit-classification\\o...      3\n",
       "796  e:\\Current_Workdir\\palm-fruit-classification\\o...      3\n",
       "797  e:\\Current_Workdir\\palm-fruit-classification\\o...      3\n",
       "798  e:\\Current_Workdir\\palm-fruit-classification\\o...      3\n",
       "799  e:\\Current_Workdir\\palm-fruit-classification\\o...      3\n",
       "\n",
       "[800 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e:\\Current_Workdir\\palm-fruit-classification\\o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e:\\Current_Workdir\\palm-fruit-classification\\o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e:\\Current_Workdir\\palm-fruit-classification\\o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e:\\Current_Workdir\\palm-fruit-classification\\o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e:\\Current_Workdir\\palm-fruit-classification\\o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>e:\\Current_Workdir\\palm-fruit-classification\\o...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>e:\\Current_Workdir\\palm-fruit-classification\\o...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>e:\\Current_Workdir\\palm-fruit-classification\\o...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>e:\\Current_Workdir\\palm-fruit-classification\\o...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>e:\\Current_Workdir\\palm-fruit-classification\\o...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                image  label\n",
       "0   e:\\Current_Workdir\\palm-fruit-classification\\o...      0\n",
       "1   e:\\Current_Workdir\\palm-fruit-classification\\o...      0\n",
       "2   e:\\Current_Workdir\\palm-fruit-classification\\o...      0\n",
       "3   e:\\Current_Workdir\\palm-fruit-classification\\o...      0\n",
       "4   e:\\Current_Workdir\\palm-fruit-classification\\o...      0\n",
       "..                                                ...    ...\n",
       "75  e:\\Current_Workdir\\palm-fruit-classification\\o...      3\n",
       "76  e:\\Current_Workdir\\palm-fruit-classification\\o...      3\n",
       "77  e:\\Current_Workdir\\palm-fruit-classification\\o...      3\n",
       "78  e:\\Current_Workdir\\palm-fruit-classification\\o...      3\n",
       "79  e:\\Current_Workdir\\palm-fruit-classification\\o...      3\n",
       "\n",
       "[80 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image    object\n",
       "label     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_path.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e:\\Current_Workdir\\palm-fruit-classification\\o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e:\\Current_Workdir\\palm-fruit-classification\\o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e:\\Current_Workdir\\palm-fruit-classification\\o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e:\\Current_Workdir\\palm-fruit-classification\\o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e:\\Current_Workdir\\palm-fruit-classification\\o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>e:\\Current_Workdir\\palm-fruit-classification\\o...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>e:\\Current_Workdir\\palm-fruit-classification\\o...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>e:\\Current_Workdir\\palm-fruit-classification\\o...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>e:\\Current_Workdir\\palm-fruit-classification\\o...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>e:\\Current_Workdir\\palm-fruit-classification\\o...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                image  label\n",
       "0   e:\\Current_Workdir\\palm-fruit-classification\\o...      0\n",
       "1   e:\\Current_Workdir\\palm-fruit-classification\\o...      0\n",
       "2   e:\\Current_Workdir\\palm-fruit-classification\\o...      0\n",
       "3   e:\\Current_Workdir\\palm-fruit-classification\\o...      0\n",
       "4   e:\\Current_Workdir\\palm-fruit-classification\\o...      0\n",
       "..                                                ...    ...\n",
       "75  e:\\Current_Workdir\\palm-fruit-classification\\o...      3\n",
       "76  e:\\Current_Workdir\\palm-fruit-classification\\o...      3\n",
       "77  e:\\Current_Workdir\\palm-fruit-classification\\o...      3\n",
       "78  e:\\Current_Workdir\\palm-fruit-classification\\o...      3\n",
       "79  e:\\Current_Workdir\\palm-fruit-classification\\o...      3\n",
       "\n",
       "[80 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyperparameters: env.batch_size: !!python/object:ray.tune.search.sample.Categorical\n",
      "  categories:\n",
      "  - 16\n",
      "  - 32\n",
      "  - 64\n",
      "  - 128\n",
      "  - 256\n",
      "  sampler: !!python/object:ray.tune.search.sample._Uniform {}\n",
      "model.document_transformer.checkpoint_name: microsoft/layoutlmv2-base-uncased\n",
      "model.hf_text.checkpoint_name: !!python/object:ray.tune.search.sample.Categorical\n",
      "  categories:\n",
      "  - google/electra-small-discriminator\n",
      "  - google/flan-t5-small\n",
      "  - microsoft/deberta-v3-xsmall\n",
      "  - albert-base-v2\n",
      "  - microsoft/MiniLM-L12-H384-uncased\n",
      "  sampler: !!python/object:ray.tune.search.sample._Uniform {}\n",
      "model.names:\n",
      "- ft_transformer\n",
      "- timm_image\n",
      "- hf_text\n",
      "- document_transformer\n",
      "- fusion_mlp\n",
      "model.timm_image.checkpoint_name: !!python/object:ray.tune.search.sample.Categorical\n",
      "  categories:\n",
      "  - mobilenetv3_large_100\n",
      "  - gluon_resnet18_v1b\n",
      "  - maxvit_rmlp_pico_rw_256.sw_in1k\n",
      "  sampler: !!python/object:ray.tune.search.sample._Uniform {}\n",
      "optimization.learning_rate: !!python/object:ray.tune.search.sample.Float\n",
      "  lower: 1.0e-05\n",
      "  sampler: !!python/object:ray.tune.search.sample._LogUniform\n",
      "    base: 10\n",
      "  upper: 0.01\n",
      "optimization.max_epochs: !!python/object:ray.tune.search.sample.Categorical\n",
      "  categories:\n",
      "  - 5\n",
      "  - 6\n",
      "  - 7\n",
      "  - 8\n",
      "  - 9\n",
      "  - 10\n",
      "  - 11\n",
      "  - 12\n",
      "  - 13\n",
      "  - 14\n",
      "  - 15\n",
      "  - 16\n",
      "  - 17\n",
      "  - 18\n",
      "  - 19\n",
      "  - 20\n",
      "  - 21\n",
      "  - 22\n",
      "  - 23\n",
      "  - 24\n",
      "  - 25\n",
      "  - 26\n",
      "  - 27\n",
      "  - 28\n",
      "  - 29\n",
      "  - 30\n",
      "  sampler: !!python/object:ray.tune.search.sample._Uniform {}\n",
      "optimization.optim_type: !!python/object:ray.tune.search.sample.Categorical\n",
      "  categories:\n",
      "  - adamw\n",
      "  - sgd\n",
      "  sampler: !!python/object:ray.tune.search.sample._Uniform {}\n",
      "\n",
      "hyperparameter_tune_kwargs: {\n",
      "    \"num_trials\": 512,\n",
      "    \"scheduler\": \"ASHA\",\n",
      "    \"searcher\": \"bayes\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "hyperparameters, hyperparameter_tune_kwargs = get_automm_presets(problem_type=\"default\", presets=\"medium_quality_hpo\")\n",
    "print(f\"hyperparameters: {yaml.dump(hyperparameters, allow_unicode=True, default_flow_style=False)}\")\n",
    "print(f\"hyperparameter_tune_kwargs: {json.dumps(hyperparameter_tune_kwargs, sort_keys=True, indent=4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f\"./tmp/{uuid.uuid4().hex}-automm_shopee\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "save path: e:\\Current_Workdir\\palm-fruit-classification\\old\\lemme_learn_the_framework_first\\tmp\\1b5fc25fe96b45d7a8c4ce0c0a8ce493-automm_shopee\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.11.10\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          32\n",
      "Pytorch Version:    2.4.1\n",
      "CUDA Version:       12.4\n",
      "Memory Avail:       111.01 GB / 127.91 GB (86.8%)\n",
      "Disk Space Avail:   1457.80 GB / 1863.00 GB (78.3%)\n",
      "===================================================\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t4 unique label values:  [0, 1, 2, 3]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "column_types: OrderedDict([('image', 'image_path'), ('label', 'categorical')])\n",
      "image columns: ['image']\n",
      "validation_metric_name: f1_macro\n",
      "minmax_mode: max\n",
      "Resources info for NonParallelGpuResourceCalculator: {'resources_per_job': {'cpu': 32, 'gpu': 1}, 'num_parallel_jobs': 1.0, 'batches': 5, 'cpu_per_job': 32, 'gpu_per_job': 1}\n",
      "resources_per_trial to be dispatched by ray tune: {'cpu': 32, 'gpu': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-12-04 14:31:00</td></tr>\n",
       "<tr><td>Running for: </td><td>00:04:43.94        </td></tr>\n",
       "<tr><td>Memory:      </td><td>19.4/127.9 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=3<br>Bracket: Iter 4096.000: None | Iter 1024.000: None | Iter 256.000: None | Iter 64.000: None | Iter 16.000: 0.9082339107990265 | Iter 4.000: 0.8642317652702332 | Iter 1.000: 0.29291486740112305<br>Logical resource usage: 32.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name  </th><th>status    </th><th>loc            </th><th>model.names         </th><th>model.timm_image.che\n",
       "ckpoint_name                     </th><th style=\"text-align: right;\">            optimization.learnin\n",
       "g_rate</th><th style=\"text-align: right;\">   optimization.max_epo\n",
       "chs</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  val_f1_macro</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>6ddc1dca    </td><td>TERMINATED</td><td>127.0.0.1:9896 </td><td>(&#x27;timm_image&#x27;, _3fc0</td><td>mobilenetv3_lar_6ce0</td><td style=\"text-align: right;\">0.000802508</td><td style=\"text-align: right;\">12</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         85.9622</td><td style=\"text-align: right;\">      0.93084 </td></tr>\n",
       "<tr><td>c9f4aa94    </td><td>TERMINATED</td><td>127.0.0.1:36296</td><td>(&#x27;timm_image&#x27;, _0b80</td><td>ghostnet_100        </td><td style=\"text-align: right;\">0.000103108</td><td style=\"text-align: right;\">16</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         25.0382</td><td style=\"text-align: right;\">      0.22842 </td></tr>\n",
       "<tr><td>20dd65f6    </td><td>TERMINATED</td><td>127.0.0.1:3780 </td><td>(&#x27;timm_image&#x27;, _f740</td><td>mobilenetv3_lar_6ce0</td><td style=\"text-align: right;\">0.000672537</td><td style=\"text-align: right;\">19</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         24.055 </td><td style=\"text-align: right;\">      0.265657</td></tr>\n",
       "<tr><td>fc18d177    </td><td>TERMINATED</td><td>127.0.0.1:38068</td><td>(&#x27;timm_image&#x27;, _db00</td><td>mobilenetv3_lar_6ce0</td><td style=\"text-align: right;\">0.000126811</td><td style=\"text-align: right;\">14</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         24.3365</td><td style=\"text-align: right;\">      0.222794</td></tr>\n",
       "<tr><td>97acd83e    </td><td>TERMINATED</td><td>127.0.0.1:16772</td><td>(&#x27;timm_image&#x27;, _02c0</td><td>mobilenetv3_lar_6ce0</td><td style=\"text-align: right;\">0.000790609</td><td style=\"text-align: right;\">12</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         69.4793</td><td style=\"text-align: right;\">      0.918638</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name  </th><th>should_checkpoint  </th><th style=\"text-align: right;\">  val_f1_macro</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>20dd65f6    </td><td>True               </td><td style=\"text-align: right;\">      0.265657</td></tr>\n",
       "<tr><td>6ddc1dca    </td><td>True               </td><td style=\"text-align: right;\">      0.93084 </td></tr>\n",
       "<tr><td>97acd83e    </td><td>True               </td><td style=\"text-align: right;\">      0.918638</td></tr>\n",
       "<tr><td>c9f4aa94    </td><td>True               </td><td style=\"text-align: right;\">      0.22842 </td></tr>\n",
       "<tr><td>fc18d177    </td><td>True               </td><td style=\"text-align: right;\">      0.222794</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing non-optimal trials and only keep the best one.\n",
      "image augmentation space [<identity>, <AutoContrast>, <Equalize>, <Rotate>, <Solarize>, <Color>, <Posterize>, <Contrast>, <Brightness>, <Sharpness>, <ShearX>, <ShearY>, <TranslateX>, <TranslateY>]\n",
      "output_shape: 4\n",
      "initializing mobilenetv3_large_100\n",
      "mix_choice: all_logits\n",
      "outer layers are treated as head: ['head.weight', 'head.bias']\n",
      "Start to fuse 3 checkpoints via the greedy soup algorithm.\n",
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\autogluon\\multimodal\\learners\\base.py:2111: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=torch.device(\"cpu\"))[\"state_dict\"]\n",
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 5/5 [00:00<00:00,  9.07it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\autogluon\\multimodal\\utils\\checkpoint.py:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(per_path, map_location=torch.device(\"cpu\"))[\"state_dict\"]\n",
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 14.18it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\autogluon\\multimodal\\utils\\checkpoint.py:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(per_path, map_location=torch.device(\"cpu\"))[\"state_dict\"]\n",
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 14.83it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programs\\miniforge3\\envs\\autogluon_stable_112\\Lib\\site-packages\\autogluon\\multimodal\\utils\\checkpoint.py:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(per_path, map_location=torch.device(\"cpu\"))[\"state_dict\"]\n",
      "AutoMM has created your model. 🎉🎉🎉\n",
      "\n",
      "To load the model, use the code below:\n",
      "    ```python\n",
      "    from autogluon.multimodal import MultiModalPredictor\n",
      "    predictor = MultiModalPredictor.load(\"e:\\Current_Workdir\\palm-fruit-classification\\old\\lemme_learn_the_framework_first\\tmp\\1b5fc25fe96b45d7a8c4ce0c0a8ce493-automm_shopee\")\n",
      "    ```\n",
      "\n",
      "If you are not satisfied with the model, try to increase the training time, \n",
      "adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\n",
      "or post issues on GitHub (https://github.com/autogluon/autogluon/issues).\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.multimodal.predictor.MultiModalPredictor at 0x1e71c780050>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_hpo = MultiModalPredictor(label=\"label\", eval_metric=\"f1_macro\", path=model_path)\n",
    "predictor_hpo.set_verbosity(4)\n",
    "\n",
    "hyperparameters = {\n",
    "            \"optimization.learning_rate\": tune.uniform(0.00005, 0.001),\n",
    "            \"optimization.max_epochs\": tune.randint(10,20),\n",
    "            \"model.timm_image.checkpoint_name\": tune.choice([\"ghostnet_100\",\n",
    "                                                             \"mobilenetv3_large_100\"])\n",
    "}\n",
    "hyperparameter_tune_kwargs = {\n",
    "    \"searcher\": \"bayes\", # random\n",
    "    \"scheduler\": \"ASHA\",\n",
    "    \"num_trials\": 5,\n",
    "    \"num_to_keep\": 2,\n",
    "}\n",
    "\n",
    "# Run the HPO fit\n",
    "predictor_hpo.fit(\n",
    "    train_data=train_data_path,\n",
    "    hyperparameters=hyperparameters,\n",
    "    hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowInvalid",
     "evalue": "URI has empty scheme: 'lemme_learn_the_framework_first/tmp/2d1b4acbd01d4663ba8610070b2ca70e-automm_shopee'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtune\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExperimentAnalysis\n\u001b[1;32m----> 3\u001b[0m analysis \u001b[38;5;241m=\u001b[39m \u001b[43mExperimentAnalysis\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlemme_learn_the_framework_first/tmp/2d1b4acbd01d4663ba8610070b2ca70e-automm_shopee\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m analysis\n",
      "File \u001b[1;32me:\\Programs\\miniforge3\\envs\\autogluon_112\\lib\\site-packages\\ray\\tune\\analysis\\experiment_analysis.py:87\u001b[0m, in \u001b[0;36mExperimentAnalysis.__init__\u001b[1;34m(self, experiment_checkpoint_path, storage_filesystem, trials, default_metric, default_mode)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fs \u001b[38;5;241m=\u001b[39m storage_filesystem\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 87\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fs, experiment_checkpoint_path \u001b[38;5;241m=\u001b[39m \u001b[43mget_fs_and_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperiment_checkpoint_path\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# Find the json state file.\u001b[39;00m\n\u001b[0;32m     92\u001b[0m experiment_checkpoint_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(experiment_checkpoint_path)\n",
      "File \u001b[1;32me:\\Programs\\miniforge3\\envs\\autogluon_112\\lib\\site-packages\\ray\\train\\_internal\\storage.py:306\u001b[0m, in \u001b[0;36mget_fs_and_path\u001b[1;34m(storage_path, storage_filesystem)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m storage_filesystem:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m storage_filesystem, storage_path\n\u001b[1;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpyarrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFileSystem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Programs\\miniforge3\\envs\\autogluon_112\\lib\\site-packages\\pyarrow\\_fs.pyx:477\u001b[0m, in \u001b[0;36mpyarrow._fs.FileSystem.from_uri\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32me:\\Programs\\miniforge3\\envs\\autogluon_112\\lib\\site-packages\\pyarrow\\error.pxi:155\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32me:\\Programs\\miniforge3\\envs\\autogluon_112\\lib\\site-packages\\pyarrow\\error.pxi:92\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowInvalid\u001b[0m: URI has empty scheme: 'lemme_learn_the_framework_first/tmp/2d1b4acbd01d4663ba8610070b2ca70e-automm_shopee'"
     ]
    }
   ],
   "source": [
    "from ray.tune import ExperimentAnalysis\n",
    "\n",
    "analysis = ExperimentAnalysis(\"lemme_learn_the_framework_first/tmp/2d1b4acbd01d4663ba8610070b2ca70e-automm_shopee\")\n",
    "analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No experiment snapshot file of form 'experiment_state-*.json' was found at: (local, E:/Current_Workdir/palm-fruit-classification/lemme_learn_the_framework_first/tmp/903a01351f4d489581053bd484381b7a-automm_shopee)\nPlease check if you specified the correct experiment path, which should be a combination of the `storage_path` and `name` specified in your run.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtune\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalysis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExperimentAnalysis\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Path to AutoGluon Ray tuning output\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m analysis \u001b[38;5;241m=\u001b[39m \u001b[43mExperimentAnalysis\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mE:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mCurrent_Workdir\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mpalm-fruit-classification\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mlemme_learn_the_framework_first\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mtmp\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m903a01351f4d489581053bd484381b7a-automm_shopee\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Get all trials and results\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m analysis\u001b[38;5;241m.\u001b[39mtrials:\n",
      "File \u001b[1;32me:\\Programs\\miniforge3\\envs\\autogluon_112\\lib\\site-packages\\ray\\tune\\analysis\\experiment_analysis.py:104\u001b[0m, in \u001b[0;36mExperimentAnalysis.__init__\u001b[1;34m(self, experiment_checkpoint_path, storage_filesystem, trials, default_metric, default_mode)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m experiment_json_fs_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    103\u001b[0m         pattern \u001b[38;5;241m=\u001b[39m TuneController\u001b[38;5;241m.\u001b[39mCKPT_FILE_TMPL\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 104\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    105\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo experiment snapshot file of form \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpattern\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m was found at: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    106\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fs\u001b[38;5;241m.\u001b[39mtype_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experiment_fs_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    107\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease check if you specified the correct experiment path, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhich should be a combination of the `storage_path` and `name` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    109\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecified in your run.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    110\u001b[0m         )\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experiment_json_fs_path \u001b[38;5;241m=\u001b[39m experiment_json_fs_path\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials \u001b[38;5;241m=\u001b[39m trials \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_trials()\n",
      "\u001b[1;31mValueError\u001b[0m: No experiment snapshot file of form 'experiment_state-*.json' was found at: (local, E:/Current_Workdir/palm-fruit-classification/lemme_learn_the_framework_first/tmp/903a01351f4d489581053bd484381b7a-automm_shopee)\nPlease check if you specified the correct experiment path, which should be a combination of the `storage_path` and `name` specified in your run."
     ]
    }
   ],
   "source": [
    "from ray.tune.analysis import ExperimentAnalysis\n",
    "\n",
    "# Path to AutoGluon Ray tuning output\n",
    "analysis = ExperimentAnalysis(\"E:\\\\Current_Workdir\\\\palm-fruit-classification\\lemme_learn_the_framework_first\\\\tmp\\\\903a01351f4d489581053bd484381b7a-automm_shopee\")\n",
    "\n",
    "# Get all trials and results\n",
    "for trial in analysis.trials:\n",
    "    print(f\"Trial ID: {trial.trial_id}\")\n",
    "    print(f\"Status: {trial.status}\")\n",
    "    print(f\"Last Result: {trial.last_result}\")\n",
    "    print(f\"Log Directory: {trial.logdir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_hpo.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Path to the experiment state file\n",
    "experiment_state_path = \"E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\lemme_learn_the_framework_first\\\\tmp\\\\903a01351f4d489581053bd484381b7a-automm_shopee\\\\experiment_state-2024-12-03_15-07-17.json\"\n",
    "\n",
    "# Load the tuning results\n",
    "with open(experiment_state_path, 'r') as file:\n",
    "    experiment_data = json.load(file)\n",
    "\n",
    "# Inspect the experiment data\n",
    "print(json.dumps(experiment_data, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the experiment state file\n",
    "experiment_state_path = \"E:\\\\Current_Workdir\\\\palm-fruit-classification\\\\lemme_learn_the_framework_first\\\\tmp\\\\903a01351f4d489581053bd484381b7a-automm_shopee\\\\experiment_state-2024-12-03_15-07-17.json\"\n",
    "\n",
    "# Load the tuning results\n",
    "with open(experiment_state_path, 'r') as file:\n",
    "    experiment_data = json.load(file)\n",
    "\n",
    "# Extract trial data from the JSON\n",
    "trials = experiment_data.get(\"trials\", {})\n",
    "\n",
    "# Prepare a list to hold parsed trial data\n",
    "parsed_data = []\n",
    "\n",
    "# Iterate over trials to extract relevant information\n",
    "for trial_id, trial_info in trials.items():\n",
    "    trial_data = {\n",
    "        \"Trial ID\": trial_id,\n",
    "        \"Status\": trial_info.get(\"status\"),\n",
    "        \"Start Time\": trial_info.get(\"start_time\"),\n",
    "        \"End Time\": trial_info.get(\"end_time\"),\n",
    "        \"Metric (e.g., val_f1_macro)\": trial_info.get(\"metric_results\", {}).get(\"val_f1_macro\"),\n",
    "    }\n",
    "    # Add additional details if needed (e.g., hyperparameters)\n",
    "    hyperparams = trial_info.get(\"config\", {})\n",
    "    for key, value in hyperparams.items():\n",
    "        trial_data[f\"Hyperparam: {key}\"] = value\n",
    "    \n",
    "    # Append parsed trial data\n",
    "    parsed_data.append(trial_data)\n",
    "\n",
    "# Create a Pandas DataFrame from the parsed data\n",
    "df = pd.DataFrame(parsed_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Save the DataFrame to a CSV file if needed\n",
    "df.to_csv(\"parsed_experiment_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Define the file path\n",
    "file_path = r\"E:\\Current_Workdir\\palm-fruit-classification\\lemme_learn_the_framework_first\\tmp\\903a01351f4d489581053bd484381b7a-automm_shopee\\searcher-state-2024-12-03_15-07-17.pkl\"\n",
    "\n",
    "# Open the file and load its content\n",
    "with open(file_path, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "# Now you can use 'data', which contains the contents of the pickle file\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Define the file path\n",
    "file_path = r\"E:\\Current_Workdir\\palm-fruit-classification\\lemme_learn_the_framework_first\\tmp\\903a01351f4d489581053bd484381b7a-automm_shopee\\tuner.pkl\"\n",
    "\n",
    "# Open the file and load its content\n",
    "with open(file_path, 'rb') as file:\n",
    "    tuner_data = pickle.load(file)\n",
    "\n",
    "# Now you can use 'tuner_data', which contains the contents of the pickle file\n",
    "print(tuner_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Define the file path\n",
    "file_path = r\"E:\\Current_Workdir\\palm-fruit-classification\\lemme_learn_the_framework_first\\tmp\\903a01351f4d489581053bd484381b7a-automm_shopee\\params.pkl\"\n",
    "\n",
    "# Open the file and load its content\n",
    "with open(file_path, 'rb') as file:\n",
    "    params_data = pickle.load(file)\n",
    "\n",
    "# Now you can use 'params_data', which contains the contents of the pickle file\n",
    "print(params_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Define the file path\n",
    "file_path = r\"E:\\Current_Workdir\\palm-fruit-classification\\lemme_learn_the_framework_first\\tmp\\903a01351f4d489581053bd484381b7a-automm_shopee\\experiment_state-2024-12-03_15-07-17.json\"\n",
    "\n",
    "# Open the file and load its content\n",
    "with open(file_path, 'r') as file:\n",
    "    experiment_data = json.load(file)\n",
    "\n",
    "# Now you can use 'experiment_data', which contains the contents of the JSON file\n",
    "print(experiment_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logs.leaderboard())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_summary = predictor_hpo.fit_summary(verbosity=4, show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fit_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fit_summary.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_hpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load pretrained checkpoint: E:\\Current_Workdir\\palm-fruit-classification\\lemme_learn_the_framework_first\\tmp\\744330067ebe4b97b0b22fcf1b4d0fcf-automm_shopee\\model.ckpt\n"
     ]
    }
   ],
   "source": [
    "predictor = MultiModalPredictor.load(\"E:/Current_Workdir/palm-fruit-classification/lemme_learn_the_framework_first/tmp/744330067ebe4b97b0b22fcf1b4d0fcf-automm_shopee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on MultiModalPredictor in module autogluon.multimodal.predictor object:\n",
      "\n",
      "class MultiModalPredictor(builtins.object)\n",
      " |  MultiModalPredictor(label: 'Optional[str]' = None, problem_type: 'Optional[str]' = None, query: 'Optional[Union[str, List[str]]]' = None, response: 'Optional[Union[str, List[str]]]' = None, match_label: 'Optional[Union[int, str]]' = None, presets: 'Optional[str]' = None, eval_metric: 'Optional[Union[str, Scorer]]' = None, hyperparameters: 'Optional[dict]' = None, path: 'Optional[str]' = None, verbosity: 'Optional[int]' = 2, num_classes: 'Optional[int]' = None, classes: 'Optional[list]' = None, warn_if_exist: 'Optional[bool]' = True, enable_progress_bar: 'Optional[bool]' = None, pretrained: 'Optional[bool]' = True, validation_metric: 'Optional[str]' = None, sample_data_path: 'Optional[str]' = None)\n",
      " |  \n",
      " |  AutoMM is designed to simplify the fine-tuning of foundation models\n",
      " |  for downstream applications with just three lines of code.\n",
      " |  AutoMM seamlessly integrates with popular model zoos such as\n",
      " |  `HuggingFace Transformers <https://github.com/huggingface/transformers>`_,\n",
      " |  `TIMM <https://github.com/huggingface/pytorch-image-models>`_,\n",
      " |  and `MMDetection <https://github.com/open-mmlab/mmdetection>`_,\n",
      " |  accommodating a diverse range of data modalities,\n",
      " |  including image, text, tabular, and document data, whether used individually or in combination.\n",
      " |  It offers support for an array of tasks, encompassing classification, regression,\n",
      " |  object detection, named entity recognition, semantic matching, and image segmentation.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, label: 'Optional[str]' = None, problem_type: 'Optional[str]' = None, query: 'Optional[Union[str, List[str]]]' = None, response: 'Optional[Union[str, List[str]]]' = None, match_label: 'Optional[Union[int, str]]' = None, presets: 'Optional[str]' = None, eval_metric: 'Optional[Union[str, Scorer]]' = None, hyperparameters: 'Optional[dict]' = None, path: 'Optional[str]' = None, verbosity: 'Optional[int]' = 2, num_classes: 'Optional[int]' = None, classes: 'Optional[list]' = None, warn_if_exist: 'Optional[bool]' = True, enable_progress_bar: 'Optional[bool]' = None, pretrained: 'Optional[bool]' = True, validation_metric: 'Optional[str]' = None, sample_data_path: 'Optional[str]' = None)\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      label\n",
      " |          Name of one pd.DataFrame column that contains the target variable to predict.\n",
      " |      problem_type\n",
      " |          Type of problem. We support standard problems like\n",
      " |      \n",
      " |          - 'binary': Binary classification\n",
      " |          - 'multiclass': Multi-class classification\n",
      " |          - 'regression': Regression\n",
      " |          - 'classification': Classification problems include 'binary' and 'multiclass' classification.\n",
      " |      \n",
      " |          In addition, we support advanced problems such as\n",
      " |      \n",
      " |          - 'object_detection': Object detection\n",
      " |          - 'ner' or 'named_entity_recognition': Named entity extraction\n",
      " |          - 'text_similarity': Text-text semantic matching\n",
      " |          - 'image_similarity': Image-image semantic matching\n",
      " |          - 'image_text_similarity': Text-image semantic matching\n",
      " |          - 'feature_extraction': Extracting feature (only support inference)\n",
      " |          - 'zero_shot_image_classification': Zero-shot image classification (only support inference)\n",
      " |          - 'few_shot_classification': Few-shot classification for image or text data.\n",
      " |          - 'semantic_segmentation': Semantic segmentation with Segment Anything Model.\n",
      " |      \n",
      " |          For certain problem types, the default behavior is to load a pretrained model based on\n",
      " |          the presets / hyperparameters and the predictor can do zero-shot inference\n",
      " |          (running inference without .fit()). Those include the following\n",
      " |          problem types:\n",
      " |      \n",
      " |          - 'object_detection'\n",
      " |          - 'text_similarity'\n",
      " |          - 'image_similarity'\n",
      " |          - 'image_text_similarity'\n",
      " |          - 'feature_extraction'\n",
      " |          - 'zero_shot_image_classification'\n",
      " |      \n",
      " |      query\n",
      " |          Name of one pd.DataFrame column that has the query data in semantic matching tasks.\n",
      " |      response\n",
      " |          Name of one pd.DataFrame column that contains the response data in semantic matching tasks.\n",
      " |          If no label column is provided, the query and response pairs in\n",
      " |          one pd.DataFrame row are assumed to be positive pairs.\n",
      " |      match_label\n",
      " |          The label class that indicates the <query, response> pair is counted as a \"match\".\n",
      " |          This is used when the task belongs to semantic matching, and the labels are binary.\n",
      " |          For example, the label column can contain [\"duplicate\", \"not duplicate\"] in a duplicate detection task.\n",
      " |          The match_label should be \"duplicate\" since it means that two items match.\n",
      " |      presets\n",
      " |          Presets regarding model quality, e.g., 'best_quality', 'high_quality' (default), and 'medium_quality'.\n",
      " |          Each quality has its corresponding HPO presets: 'best_quality_hpo', 'high_quality_hpo', and 'medium_quality_hpo'.\n",
      " |      eval_metric\n",
      " |          Evaluation metric name. If `eval_metric = None`, it is automatically chosen based on `problem_type`.\n",
      " |          Defaults to 'accuracy' for multiclass classification, `roc_auc` for binary classification,\n",
      " |          and 'root_mean_squared_error' for regression.\n",
      " |      hyperparameters\n",
      " |          This is to override some default configurations.\n",
      " |          For example, changing the text and image backbones can be done by formatting:\n",
      " |      \n",
      " |          a string\n",
      " |          hyperparameters = \"model.hf_text.checkpoint_name=google/electra-small-discriminator model.timm_image.checkpoint_name=swin_small_patch4_window7_224\"\n",
      " |      \n",
      " |          or a list of strings\n",
      " |          hyperparameters = [\"model.hf_text.checkpoint_name=google/electra-small-discriminator\", \"model.timm_image.checkpoint_name=swin_small_patch4_window7_224\"]\n",
      " |      \n",
      " |          or a dictionary\n",
      " |          hyperparameters = {\n",
      " |                          \"model.hf_text.checkpoint_name\": \"google/electra-small-discriminator\",\n",
      " |                          \"model.timm_image.checkpoint_name\": \"swin_small_patch4_window7_224\",\n",
      " |                      }\n",
      " |      path\n",
      " |          Path to directory where models and related artifacts should be saved.\n",
      " |          If unspecified, a time-stamped folder called \"AutogluonAutoMM/ag-[TIMESTAMP]\"\n",
      " |          will be created in the working directory.\n",
      " |          Note: To call `fit()` twice and save all results of each fit,\n",
      " |          you must specify different `path` locations or don't specify `path` at all.\n",
      " |      verbosity\n",
      " |          Verbosity levels range from 0 to 4, controlling how much logging information is printed.\n",
      " |          Higher levels correspond to more detailed print statements.\n",
      " |          You can set verbosity = 0 to suppress warnings.\n",
      " |      num_classes\n",
      " |          Number of classes (used for object detection).\n",
      " |          If this is specified and is different from the pretrained model's output shape,\n",
      " |          the model's head will be changed to have <num_classes> output.\n",
      " |      classes\n",
      " |          All the classes (used for object detection).\n",
      " |      warn_if_exist\n",
      " |          Whether to raise warning if the specified path already exists (Default True).\n",
      " |      enable_progress_bar\n",
      " |          Whether to show progress bar (default True). It would be\n",
      " |          disabled if the environment variable os.environ[\"AUTOMM_DISABLE_PROGRESS_BAR\"] is set.\n",
      " |      pretrained\n",
      " |          Whether to initialize the model with pretrained weights (default True).\n",
      " |          If False, it creates a model with random initialization.\n",
      " |      validation_metric\n",
      " |          Validation metric for selecting the best model and early-stopping during training.\n",
      " |          If not provided, it would be automatically chosen based on the problem type.\n",
      " |      sample_data_path\n",
      " |          The path to sample data from which we can infer num_classes or classes used for object detection.\n",
      " |  \n",
      " |  dump_model(self, save_path: 'Optional[str]' = None)\n",
      " |      Save model weights and config to a local directory.\n",
      " |      Model weights are saved in the file `pytorch_model.bin` (for `timm_image` or `hf_text`)\n",
      " |      or '<ckpt_name>.pth' (for `mmdet_image`).\n",
      " |      Configs are saved in the file `config.json` (for `timm_image` or `hf_text`)\n",
      " |      or  '<ckpt_name>.py' (for `mmdet_image`).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      save_path : str\n",
      " |         Path to directory where models and configs should be saved.\n",
      " |  \n",
      " |  evaluate(self, data: 'Union[pd.DataFrame, dict, list, str]', query_data: 'Optional[list]' = None, response_data: 'Optional[list]' = None, id_mappings: 'Optional[Union[Dict[str, Dict], Dict[str, pd.Series]]]' = None, metrics: 'Optional[Union[str, List[str]]]' = None, chunk_size: 'Optional[int]' = 1024, similarity_type: 'Optional[str]' = 'cosine', cutoffs: 'Optional[List[int]]' = [1, 5, 10], label: 'Optional[str]' = None, return_pred: 'Optional[bool]' = False, realtime: 'Optional[bool]' = False, eval_tool: 'Optional[str]' = None)\n",
      " |      Evaluate the model on a given dataset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data\n",
      " |          A pd.DataFrame, containing the same columns as the training data.\n",
      " |          Or a str, that is a path of the annotation file for detection.\n",
      " |      query_data\n",
      " |          Query data used for ranking.\n",
      " |      response_data\n",
      " |          Response data used for ranking.\n",
      " |      id_mappings\n",
      " |           Id-to-content mappings. The contents can be text, image, etc.\n",
      " |           This is used when data/query_data/response_data contain the query/response identifiers instead of their contents.\n",
      " |      metrics\n",
      " |          A list of metric names to report.\n",
      " |          If None, we only return the score for the stored `_eval_metric_name`.\n",
      " |      chunk_size\n",
      " |          Scan the response data by chunk_size each time. Increasing the value increases the speed, but requires more memory.\n",
      " |      similarity_type\n",
      " |          Use what function (cosine/dot_prod) to score the similarity (default: cosine).\n",
      " |      cutoffs\n",
      " |          A list of cutoff values to evaluate ranking.\n",
      " |      label\n",
      " |          The label column name in data. Some tasks, e.g., image<-->text matching, have no label column in training data,\n",
      " |          but the label column may be still required in evaluation.\n",
      " |      return_pred\n",
      " |          Whether to return the prediction result of each row.\n",
      " |      realtime\n",
      " |          Whether to do realtime inference, which is efficient for small data (default False).\n",
      " |          If provided None, we would infer it on based on the data modalities\n",
      " |          and sample number.\n",
      " |      eval_tool\n",
      " |          The eval_tool for object detection. Could be \"pycocotools\" or \"torchmetrics\".\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A dictionary with the metric names and their corresponding scores.\n",
      " |      Optionally return a pd.DataFrame of prediction results.\n",
      " |  \n",
      " |  export_onnx(self, data: 'Union[dict, pd.DataFrame]', path: 'Optional[str]' = None, batch_size: 'Optional[int]' = None, verbose: 'Optional[bool]' = False, opset_version: 'Optional[int]' = 16, truncate_long_and_double: 'Optional[bool]' = False)\n",
      " |      Export this predictor's model to an ONNX file.\n",
      " |      \n",
      " |      When `path` argument is not provided, the method would not save the model into disk.\n",
      " |      Instead, it would export the onnx model into BytesIO and return its binary as bytes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data\n",
      " |          Raw data used to trace and export the model.\n",
      " |          If this is None, will check if a processed batch is provided.\n",
      " |      path : str, default=None\n",
      " |          The export path of onnx model. If path is not provided, the method would export model to memory.\n",
      " |      batch_size\n",
      " |          The batch_size of export model's input.\n",
      " |          Normally the batch_size is a dynamic axis, so we could use a small value for faster export.\n",
      " |      verbose\n",
      " |          verbose flag in torch.onnx.export.\n",
      " |      opset_version\n",
      " |          opset_version flag in torch.onnx.export.\n",
      " |      truncate_long_and_double: bool, default False\n",
      " |          Truncate weights provided in int64 or double (float64) to int32 and float32\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      onnx_path : str or bytes\n",
      " |          A string that indicates location of the exported onnx model, if `path` argument is provided.\n",
      " |          Otherwise, would return the onnx model as bytes.\n",
      " |  \n",
      " |  extract_embedding(self, data: 'Union[pd.DataFrame, dict, list]', id_mappings: 'Optional[Union[Dict[str, Dict], Dict[str, pd.Series]]]' = None, return_masks: 'Optional[bool]' = False, as_tensor: 'Optional[bool]' = False, as_pandas: 'Optional[bool]' = False, realtime: 'Optional[bool]' = False, signature: 'Optional[str]' = None)\n",
      " |      Extract features for each sample, i.e., one row in the provided pd.DataFrame `data`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data\n",
      " |          The data to extract embeddings for. Should contain same column names as training dataset and\n",
      " |          follow same format (except for the `label` column).\n",
      " |      id_mappings\n",
      " |           Id-to-content mappings. The contents can be text, image, etc.\n",
      " |           This is used when data contain the query/response identifiers instead of their contents.\n",
      " |      return_masks\n",
      " |          If true, returns a mask dictionary, whose keys are the same as those in the features dictionary.\n",
      " |          If a sample has empty input in feature column `image_0`, the sample will has mask 0 under key `image_0`.\n",
      " |      as_tensor\n",
      " |          Whether to return a Pytorch tensor.\n",
      " |      as_pandas\n",
      " |          Whether to return the output as a pandas DataFrame (True) or numpy array (False).\n",
      " |      realtime\n",
      " |          Whether to do realtime inference, which is efficient for small data (default False).\n",
      " |          If provided None, we would infer it on based on the data modalities\n",
      " |          and sample number.\n",
      " |      signature\n",
      " |          When using matcher, it can be query or response.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Array of embeddings, corresponding to each row in the given data.\n",
      " |      It will have shape (#samples, D) where the embedding dimension D is determined\n",
      " |      by the neural network's architecture.\n",
      " |  \n",
      " |  fit(self, train_data: 'Union[pd.DataFrame, str]', presets: 'Optional[str]' = None, tuning_data: 'Optional[Union[pd.DataFrame, str]]' = None, max_num_tuning_data: 'Optional[int]' = None, id_mappings: 'Optional[Union[Dict[str, Dict], Dict[str, pd.Series]]]' = None, time_limit: 'Optional[int]' = None, save_path: 'Optional[str]' = None, hyperparameters: 'Optional[Union[str, Dict, List[str]]]' = None, column_types: 'Optional[dict]' = None, holdout_frac: 'Optional[float]' = None, teacher_predictor: 'Union[str, MultiModalPredictor]' = None, seed: 'Optional[int]' = 0, standalone: 'Optional[bool]' = True, hyperparameter_tune_kwargs: 'Optional[dict]' = None, clean_ckpts: 'Optional[bool]' = True)\n",
      " |      Fit models to predict a column of a data table (label) based on the other columns (features).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      train_data\n",
      " |          A pd.DataFrame containing training data.\n",
      " |      presets\n",
      " |          Presets regarding model quality, e.g., best_quality, high_quality, and medium_quality.\n",
      " |          Each quality has its corresponding HPO presets: 'best_quality_hpo', 'high_quality_hpo', and 'medium_quality_hpo'.\n",
      " |      tuning_data\n",
      " |          A pd.DataFrame containing validation data, which should have the same columns as the train_data.\n",
      " |          If `tuning_data = None`, `fit()` will automatically hold out some random validation data from `train_data`.\n",
      " |      max_num_tuning_data\n",
      " |          The maximum number of tuning samples (used for object detection).\n",
      " |      id_mappings\n",
      " |           Id-to-content mappings (used for semantic matching). The contents can be text, image, etc.\n",
      " |           This is used when the pd.DataFrame contains the query/response identifiers instead of their contents.\n",
      " |      time_limit\n",
      " |          How long `fit()` should run for (wall clock time in seconds).\n",
      " |          If not specified, `fit()` will run until the model has completed training.\n",
      " |      save_path\n",
      " |          Path to directory where models and artifacts should be saved.\n",
      " |      hyperparameters\n",
      " |          This is to override some default configurations.\n",
      " |          For example, changing the text and image backbones can be done by formatting:\n",
      " |      \n",
      " |          a string\n",
      " |          hyperparameters = \"model.hf_text.checkpoint_name=google/electra-small-discriminator model.timm_image.checkpoint_name=swin_small_patch4_window7_224\"\n",
      " |      \n",
      " |          or a list of strings\n",
      " |          hyperparameters = [\"model.hf_text.checkpoint_name=google/electra-small-discriminator\", \"model.timm_image.checkpoint_name=swin_small_patch4_window7_224\"]\n",
      " |      \n",
      " |          or a dictionary\n",
      " |          hyperparameters = {\n",
      " |                          \"model.hf_text.checkpoint_name\": \"google/electra-small-discriminator\",\n",
      " |                          \"model.timm_image.checkpoint_name\": \"swin_small_patch4_window7_224\",\n",
      " |                      }\n",
      " |      column_types\n",
      " |          A dictionary that maps column names to their data types.\n",
      " |          For example: `column_types = {\"item_name\": \"text\", \"image\": \"image_path\",\n",
      " |          \"product_description\": \"text\", \"height\": \"numerical\"}`\n",
      " |          may be used for a table with columns: \"item_name\", \"brand\", \"product_description\", and \"height\".\n",
      " |          If None, column_types will be automatically inferred from the data.\n",
      " |          The current supported types are:\n",
      " |              - \"image_path\": each row in this column is one image path.\n",
      " |              - \"text\": each row in this column contains text (sentence, paragraph, etc.).\n",
      " |              - \"numerical\": each row in this column contains a number.\n",
      " |              - \"categorical\": each row in this column belongs to one of K categories.\n",
      " |      holdout_frac\n",
      " |          Fraction of train_data to holdout as tuning_data for optimizing hyperparameters or\n",
      " |          early stopping (ignored unless `tuning_data = None`).\n",
      " |          Default value (if None) is selected based on the number of rows in the training data\n",
      " |          and whether hyperparameter optimization is utilized.\n",
      " |      teacher_predictor\n",
      " |          The pre-trained teacher predictor or its saved path. If provided, `fit()` can distill its\n",
      " |          knowledge to a student predictor, i.e., the current predictor.\n",
      " |      seed\n",
      " |          The random seed to be used for training (default 0).\n",
      " |      standalone\n",
      " |          Whether to save the entire model for offline deployment.\n",
      " |      hyperparameter_tune_kwargs\n",
      " |              Hyperparameter tuning strategy and kwargs (for example, how many HPO trials to run).\n",
      " |              If None, then hyperparameter tuning will not be performed.\n",
      " |                  num_trials: int\n",
      " |                      How many HPO trials to run. Either `num_trials` or `time_limit` to `fit` needs to be specified.\n",
      " |                  scheduler: Union[str, ray.tune.schedulers.TrialScheduler]\n",
      " |                      If str is passed, AutoGluon will create the scheduler for you with some default parameters.\n",
      " |                      If ray.tune.schedulers.TrialScheduler object is passed, you are responsible for initializing the object.\n",
      " |                  scheduler_init_args: Optional[dict] = None\n",
      " |                      If provided str to `scheduler`, you can optionally provide custom init_args to the scheduler\n",
      " |                  searcher: Union[str, ray.tune.search.SearchAlgorithm, ray.tune.search.Searcher]\n",
      " |                      If str is passed, AutoGluon will create the searcher for you with some default parameters.\n",
      " |                      If ray.tune.schedulers.TrialScheduler object is passed, you are responsible for initializing the object.\n",
      " |                      You don't need to worry about `metric` and `mode` of the searcher object. AutoGluon will figure it out by itself.\n",
      " |                  scheduler_init_args: Optional[dict] = None\n",
      " |                      If provided str to `searcher`, you can optionally provide custom init_args to the searcher\n",
      " |                      You don't need to worry about `metric` and `mode`. AutoGluon will figure it out by itself.\n",
      " |      clean_ckpts\n",
      " |          Whether to clean the intermediate checkpoints after training.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      An \"MultiModalPredictor\" object (itself).\n",
      " |  \n",
      " |  fit_summary(self, verbosity=0, show_plot=False)\n",
      " |      Output the training summary information from `fit()`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      verbosity : int, default = 2\n",
      " |          Verbosity levels range from 0 to 4 and control how much information is printed.\n",
      " |          verbosity = 0 for no output printing.\n",
      " |          TODO: Higher levels correspond to more detailed print statements\n",
      " |      show_plot : bool, default = False\n",
      " |          If True, shows the model summary plot in browser when verbosity > 1.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Dict containing various detailed information.\n",
      " |      We do not recommend directly printing this dict as it may be very large.\n",
      " |  \n",
      " |  get_num_gpus(self)\n",
      " |      Get the number of GPUs from config.\n",
      " |  \n",
      " |  list_supported_models(self, pretrained=True)\n",
      " |      List supported models for each problem type.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      pretrained : bool, default = True\n",
      " |          If True, only return the models with pretrained weights.\n",
      " |          If False, return all the models as long as there is model definition.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a list of model names\n",
      " |  \n",
      " |  optimize_for_inference(self, providers: 'Optional[Union[dict, List[str]]]' = None)\n",
      " |      Optimize the predictor's model for inference.\n",
      " |      \n",
      " |      Under the hood, the implementation would convert the PyTorch module into an ONNX module, so that\n",
      " |      we can leverage efficient execution providers in onnxruntime for faster inference.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      providers : dict or str, default=None\n",
      " |          A list of execution providers for model prediction in onnxruntime.\n",
      " |      \n",
      " |          By default, the providers argument is None. The method would generate an ONNX module that\n",
      " |          would perform model inference with TensorrtExecutionProvider in onnxruntime, if tensorrt\n",
      " |          package is properly installed. Otherwise, the onnxruntime would fallback to use CUDA or CPU\n",
      " |          execution providers instead.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      onnx_module : OnnxModule\n",
      " |          The onnx-based module that can be used to replace predictor._model for model inference.\n",
      " |  \n",
      " |  predict(self, data: 'Union[pd.DataFrame, dict, list, str]', candidate_data: 'Optional[Union[pd.DataFrame, dict, list]]' = None, id_mappings: 'Optional[Union[Dict[str, Dict], Dict[str, pd.Series]]]' = None, as_pandas: 'Optional[bool]' = None, realtime: 'Optional[bool]' = False, save_results: 'Optional[bool]' = None)\n",
      " |      Predict the label column values for new data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data\n",
      " |          The data to make predictions for. Should contain same column names as training data and\n",
      " |          follow same format (except for the `label` column).\n",
      " |      candidate_data\n",
      " |          The candidate data from which to search the query data's matches.\n",
      " |      id_mappings\n",
      " |           Id-to-content mappings. The contents can be text, image, etc.\n",
      " |           This is used when data contain the query/response identifiers instead of their contents.\n",
      " |      as_pandas\n",
      " |          Whether to return the output as a pandas DataFrame(Series) (True) or numpy array (False).\n",
      " |      realtime\n",
      " |          Whether to do realtime inference, which is efficient for small data (default False).\n",
      " |          If provided None, we would infer it on based on the data modalities\n",
      " |          and sample number.\n",
      " |      save_results\n",
      " |          Whether to save the prediction results (only works for detection now)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Array of predictions, one corresponding to each row in given dataset.\n",
      " |  \n",
      " |  predict_proba(self, data: 'Union[pd.DataFrame, dict, list]', candidate_data: 'Optional[Union[pd.DataFrame, dict, list]]' = None, id_mappings: 'Optional[Union[Dict[str, Dict], Dict[str, pd.Series]]]' = None, as_pandas: 'Optional[bool]' = None, as_multiclass: 'Optional[bool]' = True, realtime: 'Optional[bool]' = False)\n",
      " |      Predict class probabilities rather than class labels.\n",
      " |      Note that this is only for the classification tasks.\n",
      " |      Calling it for a regression task will throw an exception.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data\n",
      " |          The data to make predictions for. Should contain same column names as training data and\n",
      " |            follow same format (except for the `label` column).\n",
      " |      candidate_data\n",
      " |          The candidate data from which to search the query data's matches.\n",
      " |      id_mappings\n",
      " |           Id-to-content mappings. The contents can be text, image, etc.\n",
      " |           This is used when data contain the query/response identifiers instead of their contents.\n",
      " |      as_pandas\n",
      " |          Whether to return the output as a pandas DataFrame(Series) (True) or numpy array (False).\n",
      " |      as_multiclass\n",
      " |          Whether to return the probability of all labels or\n",
      " |          just return the probability of the positive class for binary classification problems.\n",
      " |      realtime\n",
      " |          Whether to do realtime inference, which is efficient for small data (default False).\n",
      " |          If provided None, we would infer it on based on the data modalities\n",
      " |          and sample number.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Array of predicted class-probabilities, corresponding to each row in the given data.\n",
      " |      When as_multiclass is True, the output will always have shape (#samples, #classes).\n",
      " |      Otherwise, the output will have shape (#samples,)\n",
      " |  \n",
      " |  save(self, path: 'str', standalone: 'Optional[bool]' = True)\n",
      " |      Save this predictor to file in directory specified by `path`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path\n",
      " |          The directory to save this predictor.\n",
      " |      standalone\n",
      " |          Whether to save the downloaded model for offline deployment.\n",
      " |          When standalone = True, save the transformers.CLIPModel and transformers.AutoModel to os.path.join(path,model_name),\n",
      " |          and reset the associate model.model_name.checkpoint_name start with `local://` in config.yaml.\n",
      " |          When standalone = False, the saved artifact may require an online environment to process in load().\n",
      " |  \n",
      " |  set_num_gpus(self, num_gpus)\n",
      " |      Set the number of GPUs in config.\n",
      " |  \n",
      " |  set_verbosity(self, verbosity: 'int')\n",
      " |      Set the verbosity level of the log.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      verbosity\n",
      " |          The verbosity level.\n",
      " |      \n",
      " |          0 --> only errors\n",
      " |          1 --> only warnings and critical print statements\n",
      " |          2 --> key print statements which should be shown by default\n",
      " |          3 --> more-detailed printing\n",
      " |          4 --> everything\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  load(path: 'str', resume: 'Optional[bool]' = False, verbosity: 'Optional[int]' = 3) from builtins.type\n",
      " |      Load a predictor object from a directory specified by `path`. The to-be-loaded predictor\n",
      " |      can be completely or partially trained by .fit(). If a previous training has completed,\n",
      " |      it will load the checkpoint `model.ckpt`. Otherwise, if a previous training accidentally\n",
      " |      collapses in the middle, it can load the `last.ckpt` checkpoint by setting `resume=True`.\n",
      " |      It also supports loading one specific checkpoint given its path.\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |          :meth:`autogluon.multimodal.MultiModalPredictor.load` uses `pickle` module implicitly, which is known to\n",
      " |          be insecure. It is possible to construct malicious pickle data which will execute arbitrary code during\n",
      " |          unpickling. Never load data that could have come from an untrusted source, or that could have been tampered\n",
      " |          with. **Only load data you trust.**\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path\n",
      " |          The directory to load the predictor object.\n",
      " |      resume\n",
      " |          Whether to resume training from `last.ckpt`. This is useful when a training was accidentally\n",
      " |          broken during the middle, and we want to resume the training from the last saved checkpoint.\n",
      " |      verbosity\n",
      " |          Verbosity levels range from 0 to 4 and control how much information is printed.\n",
      " |          Higher levels correspond to more detailed print statements.\n",
      " |          You can set verbosity = 0 to suppress warnings.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      The loaded predictor object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  class_labels\n",
      " |      The original name of the class labels.\n",
      " |      For example, the tabular data may contain classes equal to\n",
      " |      \"entailment\", \"contradiction\", \"neutral\". Internally, these will be converted to\n",
      " |      0, 1, 2, ...\n",
      " |      This function returns the original names of these raw labels.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      List that contain the class names. It will be None if it's not a classification problem.\n",
      " |  \n",
      " |  classes\n",
      " |      Object classes for the object detection problem type.\n",
      " |  \n",
      " |  column_types\n",
      " |      Column types in the pd.DataFrame.\n",
      " |  \n",
      " |  eval_metric\n",
      " |      What metric is used to evaluate predictive performance.\n",
      " |  \n",
      " |  label\n",
      " |      Name of one pd.DataFrame column that contains the target variable to predict.\n",
      " |  \n",
      " |  match_label\n",
      " |      The label class that indicates the <query, response> pair is counted as \"match\" in the semantic matching tasks.\n",
      " |  \n",
      " |  model_size\n",
      " |      Returns the model size in Megabyte.\n",
      " |  \n",
      " |  path\n",
      " |      Path to directory where the model and related artifacts are stored.\n",
      " |  \n",
      " |  positive_class\n",
      " |      Name of the class label that will be mapped to 1.\n",
      " |      This is only meaningful for binary classification problems.\n",
      " |      \n",
      " |      It is useful for computing metrics such as F1 which require a positive and negative class.\n",
      " |      You may refer to https://en.wikipedia.org/wiki/F-score for more details.\n",
      " |      In binary classification, :class:`MultiModalPredictor.predict_proba(as_multiclass=False)`\n",
      " |      returns the estimated probability that each row belongs to the positive class.\n",
      " |      Will print a warning and return None if called when `predictor.problem_type != 'binary'`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      The positive class name in binary classification or None if the problem is not binary classification.\n",
      " |  \n",
      " |  problem_property\n",
      " |      Property of the problem, storing the problem type and its related properties.\n",
      " |  \n",
      " |  problem_type\n",
      " |      What type of prediction problem this predictor has been trained for.\n",
      " |  \n",
      " |  query\n",
      " |      Name of one pd.DataFrame column that has the query data in semantic matching tasks.\n",
      " |  \n",
      " |  response\n",
      " |      Name of one pd.DataFrame column that contains the response data in semantic matching tasks.\n",
      " |  \n",
      " |  total_parameters\n",
      " |      The number of model parameters.\n",
      " |  \n",
      " |  trainable_parameters\n",
      " |      The number of trainable model parameters, usually those with requires_grad=True.\n",
      " |  \n",
      " |  validation_metric\n",
      " |      Validation metric for selecting the best model and early-stopping during training.\n",
      " |      Note that the validation metric may be different from the evaluation metric.\n",
      " |  \n",
      " |  verbosity\n",
      " |      Verbosity levels range from 0 to 4 and control how much information is printed.\n",
      " |      Higher levels correspond to more detailed print statements.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = predictor.evaluate(test_data_path, metrics=[\"f1_macro\"])\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = test_data_path.iloc[0]['image']\n",
    "pil_img = Image(filename=image_path)\n",
    "display(pil_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictor.predict({'image': [image_path]})\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = predictor.predict_proba({'image': [image_path]})\n",
    "print(proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = predictor.extract_embedding({'image': [image_path]})\n",
    "print(feature[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor = MultiModalPredictor.load(\"e:\\Current_Workdir\\palm-fruit-classification\\lemme_learn_the_framework_first\\tmp\\43522911e2a447a6b911e0a9e4ff3c0b-automm_shopee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.dump_model(\"./tmp/final\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogluon_stable_112",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
